{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aaron_MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N1ssg4QksN7"
      },
      "source": [
        "''' \r\n",
        "Create a network to analyse and classify MNIST Dataset\r\n",
        "Based on Stanford Lectures and Aladdin Pearson YT\r\n",
        "Images are handdrawn numbers 1-10\r\n",
        "'''\r\n",
        "\r\n",
        "# Import Libraries\r\n",
        "import torch\r\n",
        "import torch.nn as nn  # components of neural network and loss \r\n",
        "import torch.optim as optim  # optimizers\r\n",
        "import torch.nn.functional as F  \r\n",
        "from torch.utils.data import (\r\n",
        "    DataLoader,\r\n",
        ")  # can load data into batches\r\n",
        "import torchvision.datasets as datasets  # standard datasets\r\n",
        "import torchvision.transforms as transforms  # transforms change data\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4qnOveMoWKl"
      },
      "source": [
        "# much faster training on gpu if possible\r\n",
        "# Runtime -> Change runtime type -> GPU\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRwbOnYMoV1f"
      },
      "source": [
        "# Hyperparameters\r\n",
        "in_channel = 1 # 1 input\r\n",
        "num_classes = 10 # 10 possible classes\r\n",
        "learning_rate = 0.001 # learning rate of network,  determines step of optimising process\r\n",
        "batch_size = 64 # put data in to batches\r\n",
        "num_epochs = 3 # how many loops/iterations of training data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5Zu2GP7oV3q"
      },
      "source": [
        "# Load in Data\r\n",
        "# can use standard MNIST dataset\r\n",
        "# wont be case in further networks\r\n",
        "# need to transform to tensor so network can process it\r\n",
        "train_dataset = datasets.MNIST(\r\n",
        "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\r\n",
        ")\r\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\r\n",
        "test_dataset = datasets.MNIST(\r\n",
        "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\r\n",
        ")\r\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNM8X_GcoVzE"
      },
      "source": [
        "# network\r\n",
        "class CNN(nn.Module):\r\n",
        "    def __init__(self, in_channels=1, num_classes=10): # input 1 image -> 1 of 10 possible classes\r\n",
        "        super(CNN, self).__init__()\r\n",
        "        # conv layers extract features out of input to feature maps\r\n",
        "        self.conv1 = nn.Conv2d(\r\n",
        "            in_channels=1,\r\n",
        "            out_channels=8,\r\n",
        "            kernel_size=(3, 3),\r\n",
        "            stride=(1, 1),\r\n",
        "            padding=(1, 1),\r\n",
        "        )\r\n",
        "        # pooling layers reduce spatial dimensions\r\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\r\n",
        "        self.conv2 = nn.Conv2d(\r\n",
        "            in_channels=8,\r\n",
        "            out_channels=16,\r\n",
        "            kernel_size=(3, 3),\r\n",
        "            stride=(1, 1),\r\n",
        "            padding=(1, 1),\r\n",
        "        )\r\n",
        "        # linear layer output to classify \r\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "      # call network step by step in order of processes\r\n",
        "        x = F.relu(self.conv1(x))\r\n",
        "        x = self.pool(x)\r\n",
        "        x = F.relu(self.conv2(x))\r\n",
        "        x = self.pool(x)\r\n",
        "        x = x.reshape(x.shape[0], -1)\r\n",
        "        x = self.fc1(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "# Initialize network\r\n",
        "# transfer to GPU\r\n",
        "model = CNN().to(device)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVDRXrqtoVwJ"
      },
      "source": [
        "# Loss and optimizer\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sYEi6mooVta"
      },
      "source": [
        "# Train Network\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\r\n",
        "        # Get data to cuda if possible\r\n",
        "        data = data.to(device=device)\r\n",
        "        targets = targets.to(device=device)\r\n",
        "\r\n",
        "        # forward\r\n",
        "        scores = model(data)\r\n",
        "        loss = criterion(scores, targets)\r\n",
        "\r\n",
        "        # backward\r\n",
        "        # after forward pass, go backwards to update\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # gradient descent or adam step\r\n",
        "        optimizer.step()\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu3FC54xoVjb"
      },
      "source": [
        "\r\n",
        "# load in data and check model accuracy on training/test data\r\n",
        "def test(loader, model):\r\n",
        "    if loader.dataset.train:\r\n",
        "        print(\"Checking accuracy on training data\")\r\n",
        "    else:\r\n",
        "        print(\"Checking accuracy on test data\")\r\n",
        "    # keep track of predictions\r\n",
        "    num_correct = 0\r\n",
        "    num_samples = 0\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for x, y in loader:\r\n",
        "            x = x.to(device=device)\r\n",
        "            y = y.to(device=device)\r\n",
        "\r\n",
        "            scores = model(x)\r\n",
        "            _, predictions = scores.max(1)\r\n",
        "            num_correct += (predictions == y).sum()\r\n",
        "            num_samples += predictions.size(0)\r\n",
        "        # print output\r\n",
        "        print(\r\n",
        "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\r\n",
        "        )\r\n",
        "\r\n",
        "    model.train()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFY0f5rRotSO",
        "outputId": "e641016a-cf2e-4e31-900a-5ea13784f63e"
      },
      "source": [
        "test(train_loader, model)\r\n",
        "test(test_loader, model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on training data\n",
            "Got 58832 / 60000 with accuracy 98.05\n",
            "Checking accuracy on test data\n",
            "Got 9788 / 10000 with accuracy 97.88\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}