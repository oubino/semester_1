{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lLt4AGcYHI6y",
    "outputId": "304c6f1c-7877-4d8b-cfc4-6c3c170525b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n",
      "Collecting torchviz\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.7.0+cu101)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.19.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.8)\n",
      "Building wheels for collected packages: torchviz\n",
      "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3522 sha256=864253babd2aa106df511e074dc8ecc14b7c23129059e034c7dd6f3506ca3cdd\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
      "Successfully built torchviz\n",
      "Installing collected packages: torchviz\n",
      "Successfully installed torchviz-0.0.1\n"
     ]
    }
   ],
   "source": [
    "# import pytorch libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy import stats\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision.models import AlexNet\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model_alex = AlexNet() # could see if this works\n",
    "\n",
    "# import for visualisation of network\n",
    "!pip install graphviz\n",
    "!pip install torchviz\n",
    "\n",
    "\n",
    "import graphviz\n",
    "import torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "glGkWhI1OTQO",
    "outputId": "4fbd3fb2-e5fa-4e38-c197-f1a89f523b2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use GPU\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) # if on CUDA machine -> should print a CUDA device:\n",
    "!nvidia-smi  # tells you what GPU you're on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEdd_iSZSvSz",
    "outputId": "f17a9757-7e1f-46f1-ff83-f9c8a6203483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "test  train  val\n"
     ]
    }
   ],
   "source": [
    "# change path to correct folder \n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "PATH_OF_DATA= '/content/gdrive/\"My Drive\"/data/chest_xray' # see content of dataset\n",
    "!ls {PATH_OF_DATA} # datasets.ImageFolder() expects data as root/label/picture.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9UF52OUcFq8"
   },
   "outputs": [],
   "source": [
    "# custom dataset class for the images and masks\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import sklearn\n",
    "import skimage.transform as tr\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from skimage import io, transform\n",
    "\n",
    "\n",
    "class Resize(object):\n",
    "\n",
    "  def __init__(self, width, height):\n",
    "      self.width = width\n",
    "      self.height = height\n",
    "                          \n",
    "  def __call__(self, image):\n",
    "      image = asarray(image)\n",
    "      width = self.width\n",
    "      height = self.height\n",
    "\n",
    "      image = skimage.transform.resize(image, (width, height), preserve_range=True, anti_aliasing=True )\n",
    "\n",
    "      return image\n",
    "\n",
    "class Normalise(object):  \n",
    "  \"\"\" Normalise CT scan in the desired examination window\n",
    "      takes in image as numpy \"\"\"\n",
    "  \n",
    "  def __init__(self, level, window):\n",
    "      self.level = level\n",
    "      self.window = window\n",
    "                          \n",
    "  def __call__(self, image):\n",
    "      # image\n",
    "      minval = self.level - self.window/2\n",
    "      maxval = self.level + self.window/2\n",
    "      #print(image[0][160][160][0])\n",
    "      #print(image[0][160][160][1])\n",
    "      #print(image[0][160][160][2])\n",
    "      img_norm = np.clip(image, minval, maxval)\n",
    "      img_norm -= minval\n",
    "      img_norm /= self.window\n",
    "      return img_norm\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose(2,0,1)\n",
    "        image = torch.from_numpy(image).float() # dont know why images/mask casted to float here but need to do it again later\n",
    "        return image\n",
    "\n",
    "class HorizontalFlip(object):\n",
    "  \"\"\" Flip images \"\"\"\n",
    "  def __call__(self,image):\n",
    "    if random.random() <= 0.5:\n",
    "      transform = transforms.Compose([transforms.RandomHorizontalFlip(p=1)])\n",
    "      image = transform(image)\n",
    "    return image\n",
    "\n",
    "class Rotation(object):  \n",
    "  \"\"\" Random rotate images \"\"\"\n",
    "  def __call__(self,image):\n",
    "    if random.random() <= 0.5:\n",
    "      if random.random() <= 0.5:\n",
    "        image = tr.rotate(image, 10)\n",
    "      else:\n",
    "        image = tr.rotate(image,  -10)\n",
    "    return image\n",
    "\n",
    "\n",
    "class Shifting(object): \n",
    "  \"\"\" Random shift images \"\"\"\n",
    "  def __call__(self,image):\n",
    "    if random.random() <= 0.5:\n",
    "      if random.random() <= 0.5:\n",
    "        transform = tr.AffineTransform(translation = (-30,20))\n",
    "        image = tr.warp(image,transform) # default is padding with zeros\n",
    "      else:\n",
    "        transform = tr.AffineTransform(translation = (10,-30))\n",
    "        image = tr.warp(image,transform) # default is padding with zeros\n",
    "    return image\n",
    "\n",
    "class Noise(object):  # helps prevent overfitting\n",
    "  \"\"\" Random noise images \"\"\"\n",
    "  def __call__(self,image):\n",
    "    if random.random() <= 0.5:\n",
    "      image = skimage.util.random_noise(image, var = 0.000001)\n",
    "      # would this work given that mask is unchanged??\n",
    "    return image\n",
    "\n",
    "class GaussBlur(object):  # helps prevent overfitting\n",
    "  \"\"\" Gaussian blur images \"\"\"\n",
    "  def __call__(self,image):\n",
    "    if random.random() <= 0.5:\n",
    "      image = cv2.GaussianBlur(image,(3,3),0)\n",
    "      # do i want to blur the mask??\n",
    "    return image\n",
    "\n",
    "import math\n",
    "\n",
    "class RandomErasing(object):\n",
    "    '''\n",
    "    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n",
    "    -------------------------------------------------------------------------------------\n",
    "    probability: The probability that the operation will be performed.\n",
    "    sl: min erasing area\n",
    "    sh: max erasing area\n",
    "    r1: min aspect ratio\n",
    "    mean: erasing value\n",
    "    -------------------------------------------------------------------------------------\n",
    "    '''\n",
    "    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0, 0, 0]):\n",
    "        self.probability = probability\n",
    "        self.mean = mean\n",
    "        self.sl = sl\n",
    "        self.sh = sh\n",
    "        self.r1 = r1\n",
    "       \n",
    "    def __call__(self, img):\n",
    "\n",
    "        if random.uniform(0, 1) > self.probability:\n",
    "            return img\n",
    "\n",
    "        for attempt in range(100):\n",
    "            #print('height', img.shape[0])\n",
    "            #print('width', img.shape[1])\n",
    "            area = img.shape[0] * img.shape[1]\n",
    "       \n",
    "            target_area = random.uniform(self.sl, self.sh) * area\n",
    "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
    "\n",
    "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if w < img.shape[1] and h < img.shape[0]:\n",
    "                x1 = random.randint(0, img.shape[1] - w)\n",
    "                y1 = random.randint(0, img.shape[0] - h)\n",
    "                if img.shape[2] == 3:\n",
    "                    img[y1:y1+w, x1:x1+h,  0] = self.mean[0]\n",
    "                    img[y1:y1+w, x1:x1+h,  1] = self.mean[1]\n",
    "                    img[y1:y1+w, x1:x1+h,  2] = self.mean[2]\n",
    "                else:\n",
    "                    img[x1:x1+h, y1:y1+w, 0] = self.mean[0]\n",
    "                return img\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPPyepAfHiIv"
   },
   "outputs": [],
   "source": [
    "# GaussBlur(),Noise(),\n",
    "# ,transforms.RandomPerspective(distortion_scale=0.3, p=0.5), totensor, transforms.RandomErasing(p=0.5, scale=(0.05, 0.2), ratio=(0.1, 0.6), value=0, inplace=False)\n",
    "transform_test = transforms.Compose([Resize(320,320),ToTensor()])\n",
    "transform_train = transforms.Compose([Resize(320,320), RandomErasing(),  Rotation(),  ToTensor(), HorizontalFlip()]) # 175 150\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root= \"/content/gdrive/My Drive/data/chest_xray/train\", transform = transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 32, shuffle = True, num_workers = 0)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=\"/content/gdrive/My Drive/data/chest_xray/test\", transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "valset = torchvision.datasets.ImageFolder(root= \"/content/gdrive/My Drive/data/chest_xray/val\", transform = transform_test)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size = 32, shuffle = True, num_workers = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjgI-NOSrLlD"
   },
   "outputs": [],
   "source": [
    "# if want to further split training data\n",
    "\n",
    "train_size_1 = int(0.97 * len(trainset))\n",
    "train_size_2 = len(trainset) - train_size_1\n",
    "train_dataset_1, train_dataset_2 = torch.utils.data.random_split(trainset, [train_size_1, train_size_2])\n",
    "trainloader_dataset_1 = torch.utils.data.DataLoader(train_dataset_1,batch_size = 32, shuffle = True, num_workers = 0)\n",
    "trainloader_dataset_2 = torch.utils.data.DataLoader(train_dataset_2,batch_size = 32, shuffle = True, num_workers = 0)\n",
    "\n",
    "\n",
    "# i.e. to overfit to small subset of trainset use train_dataset_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bl4s56pTPnO",
    "outputId": "8e7649d7-b04e-4ecc-a756-ee490fb1b1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n",
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n",
      "{'NORMAL': 0, 'PNEUMONIA': 1}\n"
     ]
    }
   ],
   "source": [
    "# Need to see how it matches up labels\n",
    "print(trainset.class_to_idx)\n",
    "print(testset.class_to_idx)\n",
    "print(valset.class_to_idx)\n",
    "\n",
    "# Make sure this matches up order\n",
    "classes = ('Normal','Pneumonia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PW75mUgXH3es",
    "outputId": "baf7e82f-725e-4eed-9675-4796f8b658cc"
   },
   "outputs": [],
   "source": [
    "# Plot two images from training data and labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "for k in range(20):\n",
    "  examples = enumerate(trainloader) # trainloader = full trainset, trainloader_dataset_2 = small sample of trainset )\n",
    "  batch_idx, (example_data, example_targets) = next(examples)\n",
    "  #print(example_data.shape)\n",
    "  #print(example_targets.shape)c\n",
    "  #print(batch_idx)\n",
    "  for i in range(32):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(example_data[i,0], cmap = 'Greys_r', vmin=example_data[i,0].min(), vmax=example_data[i,0].max())\n",
    "    plt.show()\n",
    "    print(classes[example_targets[0]])\n",
    "  # can see that first index of [a,b] i.e. a details the number in the batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwHw5Fk9Hbem"
   },
   "outputs": [],
   "source": [
    "# define your neural network model\n",
    "\n",
    "class neural_net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(neural_net,self).__init__()\n",
    "    \n",
    "    self.pool = nn.MaxPool2d(3,3) # define pool as max 2x2\n",
    "    \n",
    "    self.dropout1 = nn.Dropout2d(p=0.2) # spatial dropout\n",
    "    self.dropout2 = nn.Dropout2d(p=0.5)\n",
    "\n",
    "    self.relu = nn.LeakyReLU()\n",
    "    self.softmax = nn.Softmax()\n",
    "    self.swish = nn.Hardswish()\n",
    "    self.adpool = nn.AdaptiveAvgPool2d(((1,1)))\n",
    "\n",
    "    self.conv1 = nn.Conv2d(3,16,3,padding =1) # i.e. input channel, output channels, Kernel size\n",
    "    self.batch1 = nn.BatchNorm2d(16) # batch normalisation\n",
    "\n",
    "    self.conv2 = nn.Conv2d(16,32,3, padding = 1)\n",
    "    self.batch2 = nn.BatchNorm2d(32)\n",
    "\n",
    "    self.conv3 = nn.Conv2d(32,64,3, padding = 1)\n",
    "    self.batch3 = nn.BatchNorm2d(64)\n",
    "\n",
    "    self.conv4 = nn.Conv2d(64,128,3, padding = 1)\n",
    "    self.batch4 = nn.BatchNorm2d(128)\n",
    "\n",
    "    self.fc1 = nn.Linear(in_features = 128*3*3, out_features = 64) # pool\n",
    "    self.fc2 = nn.Linear(in_features = 64, out_features = 16)\n",
    "    self.out = nn.Linear(in_features = 16, out_features = 2)\n",
    "  \n",
    "  def forward(self,x):\n",
    "    x = self.relu(self.pool(self.batch1(self.conv1(x))))\n",
    "    x = self.relu(self.pool(self.batch2(self.conv2(x))))\n",
    "    x = self.relu(self.pool(self.batch3(self.conv3(x))))\n",
    "    x = self.relu(self.pool(self.batch4(self.conv4(x))))\n",
    "    #x = self.dropout1(x)\n",
    "    print(x.shape)\n",
    "    x = x.view(-1,128*3*3)  \n",
    "    \n",
    "    x = self.relu(self.fc1(x))\n",
    "    x = self.relu(self.fc2(x))\n",
    "    x = self.out(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class UNET(nn.Module): # need to add bottleneck\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = self.contract_block(in_channels, 16, 3, 1)\n",
    "        self.conv2 = self.contract_block(16, 32, 3, 1)\n",
    "        self.conv3 = self.contract_block(32, 32, 3, 1)\n",
    "        self.conv4 = self.contract_block(32, 32, 3, 1)\n",
    "        self.dropout = nn.Dropout2d(p=0.5)\n",
    "        self.pool = self.pooling_layer()\n",
    "\n",
    "    \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "        self.bottleneck = self.bottleneck_block(32, 64, 128, 3, 1)    \n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = 64*10*10, out_features = 64) # pool\n",
    "        self.fc2 = nn.Linear(in_features = 64, out_features = 16)\n",
    "        self.out = nn.Linear(in_features = 16, out_features = 2)\n",
    "\n",
    "\n",
    "        # NOT FROM HERE\n",
    "        \"\"\"\n",
    "\n",
    "        self.upconv4 = self.expand_block(128*2, 128, 3, 1)\n",
    "        self.upscale_4 = self.upscale_layer(128)\n",
    "        self.upconv3 = self.expand_block(128*2, 128, 3, 1)\n",
    "        self.upscale_3 = self.upscale_layer(128)\n",
    "        self.upconv2 = self.expand_block(128*2, 64, 3, 1)\n",
    "        self.upscale_2 = self.upscale_layer(64)\n",
    "        self.final_conv = self.final_block(64*2, out_channels, 3, 1)\n",
    "        \"\"\"\n",
    "        # TO HERE\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        #print(x.shape)\n",
    "        # downsampling part\n",
    "        # encode the input image into feature representations at multiple different levels.\n",
    "        conv1 = self.conv1(x)\n",
    "        pool1 = self.pool(conv1)\n",
    "        conv2 = self.conv2(pool1)\n",
    "        drop1 = self.dropout(conv2)\n",
    "        pool2 = self.pool(drop1)\n",
    "        conv3 = self.conv3(pool2)\n",
    "        drop2 = self.dropout(conv3)\n",
    "        pool3 = self.pool(drop2)\n",
    "        conv4 = self.conv4(pool3)\n",
    "        drop4 = self.dropout(conv4)\n",
    "\n",
    "        #print(x.shape)\n",
    "  \n",
    "        \n",
    "        # bottleneck\n",
    "        # force the model to learn a compression of the input data.\n",
    "        # compressed view should only contain the “useful” information to\n",
    "        # reconstruct the input (or segmentation map).\n",
    "        pool4 = self.pool(drop4)\n",
    "        y = self.bottleneck(pool4)\n",
    "        #bottleneck2 = self.bottleneck(bottleneck1\n",
    "        \n",
    "        #print(y.shape)\n",
    "\n",
    "        # chuck in pool layer here!!!\n",
    "        y = self.pool(y)  \n",
    "\n",
    "        y = y.view(-1,64*10*10)  \n",
    "\n",
    "        #print(y.shape)\n",
    "    \n",
    "        y = self.relu(self.fc1(y))\n",
    "        y = self.relu(self.fc2(y))\n",
    "        y = self.out(y)\n",
    "        # NOT FROM HERE\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        # expand block concatenate conv4 and bottleneck output\n",
    "\n",
    "\n",
    "        upconv4 = self.upconv4(torch.cat([bottleneck1, conv4], 1))\n",
    "        upscale_conv_4 = self.upscale_4(upconv4)\n",
    "        upconv3 = self.upconv3(torch.cat([upscale_conv_4, conv3], 1))\n",
    "        upscale_conv_3 = self.upscale_3(upconv3)\n",
    "        upconv2 = self.upconv2(torch.cat([upscale_conv_3, conv2], 1))\n",
    "        upscale_conv_2 = self.upscale_2(upconv2)\n",
    "        final_layer = self.final_conv(torch.cat([upscale_conv_2, conv1], 1))\n",
    "\n",
    "        # TO HERE\n",
    "        \"\"\"\n",
    "        return y\n",
    "\n",
    "\n",
    "    def contract_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        contract = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "                                 )\n",
    "\n",
    "        return contract\n",
    "\n",
    "    def expand_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        expand = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "                            )\n",
    "        return expand\n",
    "\n",
    "    def bottleneck_block(self, in_channels, mid_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "      bottleneck = nn.Sequential(\n",
    "          nn.Conv2d(in_channels, mid_channels, kernel_size = kernel_size, stride = 1, padding = padding),#, stride = 1, padding =1),\n",
    "          nn.ReLU(),\n",
    "          nn.BatchNorm2d(mid_channels),\n",
    "          nn.Conv2d(mid_channels, mid_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "          nn.ReLU(),\n",
    "          nn.BatchNorm2d(mid_channels),\n",
    "          #nn.ConvTranspose2d(mid_channels, out_channels, kernel_size = 3, stride = 2, padding = 1, output_padding=1) #??\n",
    "          )\n",
    "      return bottleneck\n",
    "    \n",
    "    def pooling_layer(self):\n",
    "\n",
    "      pool = nn.Sequential (\n",
    "          nn.AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
    "      )\n",
    "      return pool\n",
    "\n",
    "    def upscale_layer(self, channels):\n",
    "\n",
    "      upscale = nn.Sequential(\n",
    "          nn.ConvTranspose2d(channels, channels, kernel_size = 3, stride = 2, padding = 1, output_padding=1) #??\n",
    "      )\n",
    "      return upscale\n",
    "\n",
    "\n",
    "    def final_block(self, in_channels, out_channels, kernel_size, padding):\n",
    "\n",
    "        final_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        return final_block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ENOteb8cHcfd",
    "outputId": "f3e8eb5f-b6de-4491-9c22-84dd0d089300"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 320, 320]             448\n",
      "       BatchNorm2d-2         [-1, 16, 320, 320]              32\n",
      "              ReLU-3         [-1, 16, 320, 320]               0\n",
      "            Conv2d-4         [-1, 16, 320, 320]           2,320\n",
      "       BatchNorm2d-5         [-1, 16, 320, 320]              32\n",
      "              ReLU-6         [-1, 16, 320, 320]               0\n",
      "         AvgPool2d-7         [-1, 16, 160, 160]               0\n",
      "            Conv2d-8         [-1, 32, 160, 160]           4,640\n",
      "       BatchNorm2d-9         [-1, 32, 160, 160]              64\n",
      "             ReLU-10         [-1, 32, 160, 160]               0\n",
      "           Conv2d-11         [-1, 32, 160, 160]           9,248\n",
      "      BatchNorm2d-12         [-1, 32, 160, 160]              64\n",
      "             ReLU-13         [-1, 32, 160, 160]               0\n",
      "        Dropout2d-14         [-1, 32, 160, 160]               0\n",
      "        AvgPool2d-15           [-1, 32, 80, 80]               0\n",
      "           Conv2d-16           [-1, 32, 80, 80]           9,248\n",
      "      BatchNorm2d-17           [-1, 32, 80, 80]              64\n",
      "             ReLU-18           [-1, 32, 80, 80]               0\n",
      "           Conv2d-19           [-1, 32, 80, 80]           9,248\n",
      "      BatchNorm2d-20           [-1, 32, 80, 80]              64\n",
      "             ReLU-21           [-1, 32, 80, 80]               0\n",
      "        Dropout2d-22           [-1, 32, 80, 80]               0\n",
      "        AvgPool2d-23           [-1, 32, 40, 40]               0\n",
      "           Conv2d-24           [-1, 32, 40, 40]           9,248\n",
      "      BatchNorm2d-25           [-1, 32, 40, 40]              64\n",
      "             ReLU-26           [-1, 32, 40, 40]               0\n",
      "           Conv2d-27           [-1, 32, 40, 40]           9,248\n",
      "      BatchNorm2d-28           [-1, 32, 40, 40]              64\n",
      "             ReLU-29           [-1, 32, 40, 40]               0\n",
      "        Dropout2d-30           [-1, 32, 40, 40]               0\n",
      "        AvgPool2d-31           [-1, 32, 20, 20]               0\n",
      "           Conv2d-32           [-1, 64, 20, 20]          18,496\n",
      "             ReLU-33           [-1, 64, 20, 20]               0\n",
      "      BatchNorm2d-34           [-1, 64, 20, 20]             128\n",
      "           Conv2d-35           [-1, 64, 20, 20]          36,928\n",
      "             ReLU-36           [-1, 64, 20, 20]               0\n",
      "      BatchNorm2d-37           [-1, 64, 20, 20]             128\n",
      "        AvgPool2d-38           [-1, 64, 10, 10]               0\n",
      "           Linear-39                   [-1, 64]         409,664\n",
      "             ReLU-40                   [-1, 64]               0\n",
      "           Linear-41                   [-1, 16]           1,040\n",
      "             ReLU-42                   [-1, 16]               0\n",
      "           Linear-43                    [-1, 2]              34\n",
      "================================================================\n",
      "Total params: 520,514\n",
      "Trainable params: 520,514\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.17\n",
      "Forward/backward pass size (MB): 138.82\n",
      "Params size (MB): 1.99\n",
      "Estimated Total Size (MB): 141.98\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nx = (torch.randn(32,3,320,320))\\nx = x.to(device)\\ny = model(x)\\ntorchviz.make_dot(y.mean(),params = dict(model.named_parameters()))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of neural net\n",
    "\n",
    "\n",
    "#model = neural_net()\n",
    "model = UNET(3)\n",
    "#model.to(device) # send to GPU\n",
    "\n",
    "from torchsummary import summary\n",
    "data_input_shape = (3,320,320)\n",
    "model.to(device)\n",
    "summary(model, data_input_shape)\n",
    "\n",
    "# visualise model\n",
    "\"\"\"\n",
    "x = (torch.randn(32,3,320,320))\n",
    "x = x.to(device)\n",
    "y = model(x)\n",
    "torchviz.make_dot(y.mean(),params = dict(model.named_parameters()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sELZLK8KQKpg"
   },
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "\n",
    "step = False # if false then will do cyclical\n",
    "step_size_cyclical = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdOLPKt5HcpG"
   },
   "outputs": [],
   "source": [
    "# define the loss criterion and optimizer\n",
    "\n",
    "if step == True: # step LR\n",
    "  # learning_rate_step\n",
    "  learning_rate_max = 0.1 #0.01\n",
    "  learning_rate_min = 0.006\n",
    "  epoch_range = 1\n",
    "  step_size = 2\n",
    "  gamma = 0.1 #np.exp((np.log(learning_rate_min)-np.log(learning_rate_max))/epoch_range)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(model.parameters(),lr = learning_rate_max, momentum = 0.9, weight_decay = 0.01, nesterov = True) \n",
    "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma, last_epoch=-1)\n",
    "\n",
    "if step == False: # cyclical LR\n",
    "  learning_rate_max = 0.006\n",
    "  learning_rate_min = 0.01\n",
    "  epoch_range = 10\n",
    "  step_size = step_size_cyclical\n",
    "  gamma = np.exp((np.log(learning_rate_min)-np.log(learning_rate_max))/epoch_range)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.SGD(model.parameters(),lr = learning_rate_max, momentum = 0.9, weight_decay = 0.0, nesterov = True) \n",
    "  scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,  base_lr = learning_rate_min, max_lr = learning_rate_max, step_size_up = step_size) # default is 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6405WbftzgwA"
   },
   "outputs": [],
   "source": [
    "# adam optimizer\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "weight = torch.tensor([0.9, 0.1]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight) # added weight\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay = 0.05) # use adam lr optimiser\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=2000, gamma=0.1)\n",
    "\n",
    "epoch_range = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qqOizDLSCO60"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7W2oDE_L_c6Z"
   },
   "outputs": [],
   "source": [
    "# want to be able to plot loss over time\n",
    "validation_loss_vector_y = []\n",
    "validation_loss_vector_x = []\n",
    "training_loss_vector_x = []\n",
    "training_loss_vector_y = []\n",
    "\n",
    "# plot accuracy of test vs LR\n",
    "learning_rate_vector = []\n",
    "accuracy_test_vector = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzRE9nFQHcx1",
    "outputId": "3991ba01-0f66-4672-d2ce-37d4f5d7c489"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current LR: [0.001]\n",
      "loss 0.6406130790710449\n",
      "Current LR: [0.001]\n",
      "loss 0.6551884412765503\n",
      "Current LR: [0.001]\n",
      "loss 0.8831270933151245\n",
      "Current LR: [0.001]\n",
      "loss 0.6530943512916565\n",
      "Current LR: [0.001]\n",
      "loss 0.6795185804367065\n",
      "Current LR: [0.001]\n",
      "loss 0.6833865642547607\n",
      "Current LR: [0.001]\n",
      "loss 0.4947948157787323\n",
      "Current LR: [0.001]\n",
      "loss 0.48811256885528564\n",
      "Current LR: [0.001]\n",
      "loss 0.4489832818508148\n",
      "Current LR: [0.001]\n",
      "loss 0.5848028659820557\n",
      "[1,   10] average loss for these 10 batches of 64 images is: 0.621\n",
      "saving best model\n",
      "total loss for validation set is 0.553\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.479458749294281\n",
      "Current LR: [0.001]\n",
      "loss 0.44133445620536804\n",
      "Current LR: [0.001]\n",
      "loss 0.46755802631378174\n",
      "Current LR: [0.001]\n",
      "loss 0.8524996042251587\n",
      "Current LR: [0.001]\n",
      "loss 0.38475361466407776\n",
      "Current LR: [0.001]\n",
      "loss 0.6012782454490662\n",
      "Current LR: [0.001]\n",
      "loss 0.5299407839775085\n",
      "Current LR: [0.001]\n",
      "loss 0.7008882761001587\n",
      "Current LR: [0.001]\n",
      "loss 0.439866840839386\n",
      "Current LR: [0.001]\n",
      "loss 0.4941215217113495\n",
      "[1,   20] average loss for these 10 batches of 64 images is: 0.539\n",
      "total loss for validation set is 0.788\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.44743964076042175\n",
      "Current LR: [0.001]\n",
      "loss 0.5993368029594421\n",
      "Current LR: [0.001]\n",
      "loss 0.5557714104652405\n",
      "Current LR: [0.001]\n",
      "loss 0.533196747303009\n",
      "Current LR: [0.001]\n",
      "loss 0.5551012754440308\n",
      "Current LR: [0.001]\n",
      "loss 0.5718641877174377\n",
      "Current LR: [0.001]\n",
      "loss 0.47960758209228516\n",
      "Current LR: [0.001]\n",
      "loss 0.41277194023132324\n",
      "Current LR: [0.001]\n",
      "loss 0.7734259963035583\n",
      "Current LR: [0.001]\n",
      "loss 0.38616713881492615\n",
      "[1,   30] average loss for these 10 batches of 64 images is: 0.531\n",
      "saving best model\n",
      "total loss for validation set is 0.306\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.49917060136795044\n",
      "Current LR: [0.001]\n",
      "loss 0.7909402847290039\n",
      "Current LR: [0.001]\n",
      "loss 0.4083860516548157\n",
      "Current LR: [0.001]\n",
      "loss 0.6433998942375183\n",
      "Current LR: [0.001]\n",
      "loss 0.6829869747161865\n",
      "Current LR: [0.001]\n",
      "loss 0.5957077741622925\n",
      "Current LR: [0.001]\n",
      "loss 0.5583205819129944\n",
      "Current LR: [0.001]\n",
      "loss 0.47285428643226624\n",
      "Current LR: [0.001]\n",
      "loss 0.5144792795181274\n",
      "Current LR: [0.001]\n",
      "loss 0.5447205901145935\n",
      "[1,   40] average loss for these 10 batches of 64 images is: 0.571\n",
      "total loss for validation set is 0.603\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.48663485050201416\n",
      "Current LR: [0.001]\n",
      "loss 0.5253710150718689\n",
      "Current LR: [0.001]\n",
      "loss 0.34534263610839844\n",
      "Current LR: [0.001]\n",
      "loss 0.5866028070449829\n",
      "Current LR: [0.001]\n",
      "loss 0.5389323234558105\n",
      "Current LR: [0.001]\n",
      "loss 0.3358677625656128\n",
      "Current LR: [0.001]\n",
      "loss 0.4108477532863617\n",
      "Current LR: [0.001]\n",
      "loss 0.42751044034957886\n",
      "Current LR: [0.001]\n",
      "loss 0.5139384269714355\n",
      "Current LR: [0.001]\n",
      "loss 0.4541838765144348\n",
      "[1,   50] average loss for these 10 batches of 64 images is: 0.463\n",
      "total loss for validation set is 0.374\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.5371450781822205\n",
      "Current LR: [0.001]\n",
      "loss 0.4027768075466156\n",
      "Current LR: [0.001]\n",
      "loss 0.3868117928504944\n",
      "Current LR: [0.001]\n",
      "loss 0.6202772259712219\n",
      "Current LR: [0.001]\n",
      "loss 0.5866208076477051\n",
      "Current LR: [0.001]\n",
      "loss 0.5609777569770813\n",
      "Current LR: [0.001]\n",
      "loss 0.3859560191631317\n",
      "Current LR: [0.001]\n",
      "loss 0.6194695830345154\n",
      "Current LR: [0.001]\n",
      "loss 0.7065210938453674\n",
      "Current LR: [0.001]\n",
      "loss 0.5375220775604248\n",
      "[1,   60] average loss for these 10 batches of 64 images is: 0.534\n",
      "total loss for validation set is 0.615\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.607269823551178\n",
      "Current LR: [0.001]\n",
      "loss 0.5243737101554871\n",
      "Current LR: [0.001]\n",
      "loss 0.4878917336463928\n",
      "Current LR: [0.001]\n",
      "loss 0.518913745880127\n",
      "Current LR: [0.001]\n",
      "loss 0.597235381603241\n",
      "Current LR: [0.001]\n",
      "loss 0.4534468352794647\n",
      "Current LR: [0.001]\n",
      "loss 0.4554360806941986\n",
      "Current LR: [0.001]\n",
      "loss 0.4341060221195221\n",
      "Current LR: [0.001]\n",
      "loss 0.42611968517303467\n",
      "Current LR: [0.001]\n",
      "loss 0.4839176535606384\n",
      "[1,   70] average loss for these 10 batches of 64 images is: 0.499\n",
      "total loss for validation set is 0.340\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.5336155295372009\n",
      "Current LR: [0.001]\n",
      "loss 0.4587308466434479\n",
      "Current LR: [0.001]\n",
      "loss 0.3293338119983673\n",
      "Current LR: [0.001]\n",
      "loss 0.5190159678459167\n",
      "Current LR: [0.001]\n",
      "loss 0.7293633222579956\n",
      "Current LR: [0.001]\n",
      "loss 0.4199889898300171\n",
      "Current LR: [0.001]\n",
      "loss 0.4360905885696411\n",
      "Current LR: [0.001]\n",
      "loss 0.41029515862464905\n",
      "Current LR: [0.001]\n",
      "loss 0.4819660186767578\n",
      "Current LR: [0.001]\n",
      "loss 0.4901309013366699\n",
      "[1,   80] average loss for these 10 batches of 64 images is: 0.481\n",
      "total loss for validation set is 0.412\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.43866419792175293\n",
      "Current LR: [0.001]\n",
      "loss 0.34092411398887634\n",
      "Current LR: [0.001]\n",
      "loss 0.4839288592338562\n",
      "Current LR: [0.001]\n",
      "loss 0.5179470777511597\n",
      "Current LR: [0.001]\n",
      "loss 0.3810272216796875\n",
      "Current LR: [0.001]\n",
      "loss 0.37547773122787476\n",
      "Current LR: [0.001]\n",
      "loss 0.2372913956642151\n",
      "Current LR: [0.001]\n",
      "loss 0.45394885540008545\n",
      "Current LR: [0.001]\n",
      "loss 0.35276520252227783\n",
      "Current LR: [0.001]\n",
      "loss 0.477102667093277\n",
      "[1,   90] average loss for these 10 batches of 64 images is: 0.406\n",
      "total loss for validation set is 0.659\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3288124203681946\n",
      "Current LR: [0.001]\n",
      "loss 0.5413715839385986\n",
      "Current LR: [0.001]\n",
      "loss 0.36664485931396484\n",
      "Current LR: [0.001]\n",
      "loss 0.3041018843650818\n",
      "Current LR: [0.001]\n",
      "loss 0.48026561737060547\n",
      "Current LR: [0.001]\n",
      "loss 0.4782922565937042\n",
      "Current LR: [0.001]\n",
      "loss 0.4005333185195923\n",
      "Current LR: [0.001]\n",
      "loss 0.5212050080299377\n",
      "Current LR: [0.001]\n",
      "loss 0.39555373787879944\n",
      "Current LR: [0.001]\n",
      "loss 0.4529467523097992\n",
      "[1,  100] average loss for these 10 batches of 64 images is: 0.427\n",
      "total loss for validation set is 0.549\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.4896836280822754\n",
      "Current LR: [0.001]\n",
      "loss 0.4656166434288025\n",
      "Current LR: [0.001]\n",
      "loss 0.42021411657333374\n",
      "Current LR: [0.001]\n",
      "loss 0.4689013659954071\n",
      "Current LR: [0.001]\n",
      "loss 0.26377561688423157\n",
      "Current LR: [0.001]\n",
      "loss 0.3671019971370697\n",
      "Current LR: [0.001]\n",
      "loss 0.34201598167419434\n",
      "Current LR: [0.001]\n",
      "loss 0.2935067117214203\n",
      "Current LR: [0.001]\n",
      "loss 0.5720576047897339\n",
      "Current LR: [0.001]\n",
      "loss 0.35203462839126587\n",
      "[1,  110] average loss for these 10 batches of 64 images is: 0.403\n",
      "total loss for validation set is 0.354\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3456774353981018\n",
      "Current LR: [0.001]\n",
      "loss 0.44396260380744934\n",
      "Current LR: [0.001]\n",
      "loss 0.29610395431518555\n",
      "Current LR: [0.001]\n",
      "loss 0.468985915184021\n",
      "Current LR: [0.001]\n",
      "loss 0.18729102611541748\n",
      "Current LR: [0.001]\n",
      "loss 0.31699320673942566\n",
      "Current LR: [0.001]\n",
      "loss 0.2789958417415619\n",
      "Current LR: [0.001]\n",
      "loss 0.4164365828037262\n",
      "Current LR: [0.001]\n",
      "loss 0.3498997390270233\n",
      "Current LR: [0.001]\n",
      "loss 0.41065308451652527\n",
      "[1,  120] average loss for these 10 batches of 64 images is: 0.351\n",
      "total loss for validation set is 0.454\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.4264049232006073\n",
      "Current LR: [0.001]\n",
      "loss 0.2944985330104828\n",
      "Current LR: [0.001]\n",
      "loss 0.4316568076610565\n",
      "Current LR: [0.001]\n",
      "loss 0.24927592277526855\n",
      "Current LR: [0.001]\n",
      "loss 0.3533279299736023\n",
      "Current LR: [0.001]\n",
      "loss 0.4761974513530731\n",
      "Current LR: [0.001]\n",
      "loss 0.41298311948776245\n",
      "Current LR: [0.001]\n",
      "loss 0.3894079625606537\n",
      "Current LR: [0.001]\n",
      "loss 0.43092137575149536\n",
      "Current LR: [0.001]\n",
      "loss 0.28343477845191956\n",
      "[1,  130] average loss for these 10 batches of 64 images is: 0.375\n",
      "total loss for validation set is 0.537\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.5751583576202393\n",
      "Current LR: [0.001]\n",
      "loss 0.3031165897846222\n",
      "Current LR: [0.001]\n",
      "loss 0.26916569471359253\n",
      "Current LR: [0.001]\n",
      "loss 0.39596933126449585\n",
      "Current LR: [0.001]\n",
      "loss 0.6955018639564514\n",
      "Current LR: [0.001]\n",
      "loss 0.46438178420066833\n",
      "Current LR: [0.001]\n",
      "loss 0.2829943895339966\n",
      "Current LR: [0.001]\n",
      "loss 0.404078871011734\n",
      "Current LR: [0.001]\n",
      "loss 0.30817684531211853\n",
      "Current LR: [0.001]\n",
      "loss 0.35562026500701904\n",
      "[1,  140] average loss for these 10 batches of 64 images is: 0.405\n",
      "total loss for validation set is 0.476\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2598356008529663\n",
      "Current LR: [0.001]\n",
      "loss 0.28676751255989075\n",
      "Current LR: [0.001]\n",
      "loss 0.348309189081192\n",
      "Current LR: [0.001]\n",
      "loss 0.2745111584663391\n",
      "Current LR: [0.001]\n",
      "loss 0.3744509220123291\n",
      "Current LR: [0.001]\n",
      "loss 0.5470510721206665\n",
      "Current LR: [0.001]\n",
      "loss 0.37807056307792664\n",
      "Current LR: [0.001]\n",
      "loss 0.4759286642074585\n",
      "Current LR: [0.001]\n",
      "loss 0.25916188955307007\n",
      "Current LR: [0.001]\n",
      "loss 0.45456060767173767\n",
      "[1,  150] average loss for these 10 batches of 64 images is: 0.366\n",
      "total loss for validation set is 0.366\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.38365602493286133\n",
      "Current LR: [0.001]\n",
      "loss 0.2150878757238388\n",
      "Current LR: [0.001]\n",
      "loss 0.2851676344871521\n",
      "Current LR: [0.001]\n",
      "loss 0.2939136326313019\n",
      "Current LR: [0.001]\n",
      "loss 0.3251023590564728\n",
      "Current LR: [0.001]\n",
      "loss 0.27747106552124023\n",
      "Current LR: [0.001]\n",
      "loss 0.5925029516220093\n",
      "Current LR: [0.001]\n",
      "loss 0.17725291848182678\n",
      "Current LR: [0.001]\n",
      "loss 0.4074556827545166\n",
      "Current LR: [0.001]\n",
      "loss 0.5613646507263184\n",
      "[1,  160] average loss for these 10 batches of 64 images is: 0.352\n",
      "total loss for validation set is 0.902\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3586728870868683\n",
      "Current LR: [0.001]\n",
      "loss 0.372707724571228\n",
      "Current LR: [0.001]\n",
      "loss 0.6287489533424377\n",
      "Current LR: [0.001]\n",
      "loss 0.3874348998069763\n",
      "Current LR: [0.001]\n",
      "loss 0.6283994913101196\n",
      "Current LR: [0.001]\n",
      "loss 0.42476847767829895\n",
      "Current LR: [0.001]\n",
      "loss 0.5468948483467102\n",
      "Current LR: [0.001]\n",
      "loss 0.18154117465019226\n",
      "Current LR: [0.001]\n",
      "loss 0.44480693340301514\n",
      "Current LR: [0.001]\n",
      "loss 0.431321382522583\n",
      "Current LR: [0.001]\n",
      "loss 0.20172525942325592\n",
      "Current LR: [0.001]\n",
      "loss 0.4279548227787018\n",
      "Current LR: [0.001]\n",
      "loss 0.28651708364486694\n",
      "[2,   10] average loss for these 10 batches of 64 images is: 0.396\n",
      "total loss for validation set is 0.511\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.4914710819721222\n",
      "Current LR: [0.001]\n",
      "loss 0.39181846380233765\n",
      "Current LR: [0.001]\n",
      "loss 0.4295977056026459\n",
      "Current LR: [0.001]\n",
      "loss 0.37389153242111206\n",
      "Current LR: [0.001]\n",
      "loss 0.29183030128479004\n",
      "Current LR: [0.001]\n",
      "loss 0.4383433163166046\n",
      "Current LR: [0.001]\n",
      "loss 0.43131884932518005\n",
      "Current LR: [0.001]\n",
      "loss 0.509383499622345\n",
      "Current LR: [0.001]\n",
      "loss 0.44801267981529236\n",
      "Current LR: [0.001]\n",
      "loss 0.3356401026248932\n",
      "[2,   20] average loss for these 10 batches of 64 images is: 0.414\n",
      "total loss for validation set is 0.342\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.4642108678817749\n",
      "Current LR: [0.001]\n",
      "loss 0.5962772965431213\n",
      "Current LR: [0.001]\n",
      "loss 0.5393563508987427\n",
      "Current LR: [0.001]\n",
      "loss 0.30948710441589355\n",
      "Current LR: [0.001]\n",
      "loss 0.3766104578971863\n",
      "Current LR: [0.001]\n",
      "loss 0.2884114980697632\n",
      "Current LR: [0.001]\n",
      "loss 0.5627530217170715\n",
      "Current LR: [0.001]\n",
      "loss 0.5006704330444336\n",
      "Current LR: [0.001]\n",
      "loss 0.41168880462646484\n",
      "Current LR: [0.001]\n",
      "loss 0.5335116386413574\n",
      "[2,   30] average loss for these 10 batches of 64 images is: 0.458\n",
      "total loss for validation set is 0.828\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.4173114597797394\n",
      "Current LR: [0.001]\n",
      "loss 0.4229821562767029\n",
      "Current LR: [0.001]\n",
      "loss 0.29162827134132385\n",
      "Current LR: [0.001]\n",
      "loss 0.35514330863952637\n",
      "Current LR: [0.001]\n",
      "loss 0.46539831161499023\n",
      "Current LR: [0.001]\n",
      "loss 0.2765733599662781\n",
      "Current LR: [0.001]\n",
      "loss 0.2900702655315399\n",
      "Current LR: [0.001]\n",
      "loss 0.26204386353492737\n",
      "Current LR: [0.001]\n",
      "loss 0.27718549966812134\n",
      "Current LR: [0.001]\n",
      "loss 0.3453451097011566\n",
      "[2,   40] average loss for these 10 batches of 64 images is: 0.340\n",
      "total loss for validation set is 0.487\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3129417300224304\n",
      "Current LR: [0.001]\n",
      "loss 0.33990734815597534\n",
      "Current LR: [0.001]\n",
      "loss 0.2591898739337921\n",
      "Current LR: [0.001]\n",
      "loss 0.2641523778438568\n",
      "Current LR: [0.001]\n",
      "loss 0.517316997051239\n",
      "Current LR: [0.001]\n",
      "loss 0.17328022420406342\n",
      "Current LR: [0.001]\n",
      "loss 0.43513157963752747\n",
      "Current LR: [0.001]\n",
      "loss 0.3752625584602356\n",
      "Current LR: [0.001]\n",
      "loss 0.30151912569999695\n",
      "Current LR: [0.001]\n",
      "loss 0.3679594397544861\n",
      "[2,   50] average loss for these 10 batches of 64 images is: 0.335\n",
      "total loss for validation set is 0.472\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3521139621734619\n",
      "Current LR: [0.001]\n",
      "loss 0.3574698567390442\n",
      "Current LR: [0.001]\n",
      "loss 0.4128883183002472\n",
      "Current LR: [0.001]\n",
      "loss 0.4508432149887085\n",
      "Current LR: [0.001]\n",
      "loss 0.363762766122818\n",
      "Current LR: [0.001]\n",
      "loss 0.3885066509246826\n",
      "Current LR: [0.001]\n",
      "loss 0.3090813457965851\n",
      "Current LR: [0.001]\n",
      "loss 0.18951022624969482\n",
      "Current LR: [0.001]\n",
      "loss 0.22587698698043823\n",
      "Current LR: [0.001]\n",
      "loss 0.5888328552246094\n",
      "[2,   60] average loss for these 10 batches of 64 images is: 0.364\n",
      "total loss for validation set is 0.360\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.7879824638366699\n",
      "Current LR: [0.001]\n",
      "loss 0.27519354224205017\n",
      "Current LR: [0.001]\n",
      "loss 0.35645991563796997\n",
      "Current LR: [0.001]\n",
      "loss 0.251359760761261\n",
      "Current LR: [0.001]\n",
      "loss 0.3390888273715973\n",
      "Current LR: [0.001]\n",
      "loss 0.2880096137523651\n",
      "Current LR: [0.001]\n",
      "loss 0.43624353408813477\n",
      "Current LR: [0.001]\n",
      "loss 0.46869510412216187\n",
      "Current LR: [0.001]\n",
      "loss 0.5702959299087524\n",
      "Current LR: [0.001]\n",
      "loss 0.2617626488208771\n",
      "[2,   70] average loss for these 10 batches of 64 images is: 0.404\n",
      "total loss for validation set is 2.213\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.23303698003292084\n",
      "Current LR: [0.001]\n",
      "loss 0.3479961156845093\n",
      "Current LR: [0.001]\n",
      "loss 0.39165619015693665\n",
      "Current LR: [0.001]\n",
      "loss 0.27747291326522827\n",
      "Current LR: [0.001]\n",
      "loss 0.19799193739891052\n",
      "Current LR: [0.001]\n",
      "loss 0.5141032338142395\n",
      "Current LR: [0.001]\n",
      "loss 0.8061420917510986\n",
      "Current LR: [0.001]\n",
      "loss 0.5525128245353699\n",
      "Current LR: [0.001]\n",
      "loss 0.3895770013332367\n",
      "Current LR: [0.001]\n",
      "loss 0.45982488989830017\n",
      "[2,   80] average loss for these 10 batches of 64 images is: 0.417\n",
      "total loss for validation set is 0.531\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2952340841293335\n",
      "Current LR: [0.001]\n",
      "loss 0.288507342338562\n",
      "Current LR: [0.001]\n",
      "loss 0.472028911113739\n",
      "Current LR: [0.001]\n",
      "loss 0.38986414670944214\n",
      "Current LR: [0.001]\n",
      "loss 0.35130739212036133\n",
      "Current LR: [0.001]\n",
      "loss 0.28083181381225586\n",
      "Current LR: [0.001]\n",
      "loss 0.36856716871261597\n",
      "Current LR: [0.001]\n",
      "loss 0.5069552063941956\n",
      "Current LR: [0.001]\n",
      "loss 0.3676359951496124\n",
      "Current LR: [0.001]\n",
      "loss 0.37684109807014465\n",
      "[2,   90] average loss for these 10 batches of 64 images is: 0.370\n",
      "total loss for validation set is 0.492\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.367626816034317\n",
      "Current LR: [0.001]\n",
      "loss 0.2796124517917633\n",
      "Current LR: [0.001]\n",
      "loss 0.42174383997917175\n",
      "Current LR: [0.001]\n",
      "loss 0.22667255997657776\n",
      "Current LR: [0.001]\n",
      "loss 0.2982611656188965\n",
      "Current LR: [0.001]\n",
      "loss 0.24609176814556122\n",
      "Current LR: [0.001]\n",
      "loss 0.2286672592163086\n",
      "Current LR: [0.001]\n",
      "loss 0.3286800980567932\n",
      "Current LR: [0.001]\n",
      "loss 0.3079720437526703\n",
      "Current LR: [0.001]\n",
      "loss 0.3395928740501404\n",
      "[2,  100] average loss for these 10 batches of 64 images is: 0.304\n",
      "total loss for validation set is 0.660\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.30524417757987976\n",
      "Current LR: [0.001]\n",
      "loss 0.2488359659910202\n",
      "Current LR: [0.001]\n",
      "loss 0.2525259852409363\n",
      "Current LR: [0.001]\n",
      "loss 0.20276319980621338\n",
      "Current LR: [0.001]\n",
      "loss 0.16986455023288727\n",
      "Current LR: [0.001]\n",
      "loss 0.3177182376384735\n",
      "Current LR: [0.001]\n",
      "loss 0.31104278564453125\n",
      "Current LR: [0.001]\n",
      "loss 0.22771047055721283\n",
      "Current LR: [0.001]\n",
      "loss 0.28045088052749634\n",
      "Current LR: [0.001]\n",
      "loss 0.48926860094070435\n",
      "[2,  110] average loss for these 10 batches of 64 images is: 0.281\n",
      "total loss for validation set is 0.775\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.21302209794521332\n",
      "Current LR: [0.001]\n",
      "loss 0.16676075756549835\n",
      "Current LR: [0.001]\n",
      "loss 0.4116096794605255\n",
      "Current LR: [0.001]\n",
      "loss 0.3131023347377777\n",
      "Current LR: [0.001]\n",
      "loss 0.23663325607776642\n",
      "Current LR: [0.001]\n",
      "loss 0.4428178369998932\n",
      "Current LR: [0.001]\n",
      "loss 0.2221597284078598\n",
      "Current LR: [0.001]\n",
      "loss 0.1491665244102478\n",
      "Current LR: [0.001]\n",
      "loss 0.2005552500486374\n",
      "Current LR: [0.001]\n",
      "loss 0.3096771240234375\n",
      "[2,  120] average loss for these 10 batches of 64 images is: 0.267\n",
      "total loss for validation set is 1.060\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.17925560474395752\n",
      "Current LR: [0.001]\n",
      "loss 0.37737083435058594\n",
      "Current LR: [0.001]\n",
      "loss 0.2734380066394806\n",
      "Current LR: [0.001]\n",
      "loss 0.6650012135505676\n",
      "Current LR: [0.001]\n",
      "loss 0.34810498356819153\n",
      "Current LR: [0.001]\n",
      "loss 0.21542330086231232\n",
      "Current LR: [0.001]\n",
      "loss 0.26514583826065063\n",
      "Current LR: [0.001]\n",
      "loss 0.21621538698673248\n",
      "Current LR: [0.001]\n",
      "loss 0.18735605478286743\n",
      "Current LR: [0.001]\n",
      "loss 0.48559385538101196\n",
      "[2,  130] average loss for these 10 batches of 64 images is: 0.321\n",
      "total loss for validation set is 0.460\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.34261953830718994\n",
      "Current LR: [0.001]\n",
      "loss 0.30092698335647583\n",
      "Current LR: [0.001]\n",
      "loss 0.4537754952907562\n",
      "Current LR: [0.001]\n",
      "loss 0.31130385398864746\n",
      "Current LR: [0.001]\n",
      "loss 0.4937552809715271\n",
      "Current LR: [0.001]\n",
      "loss 0.2145865559577942\n",
      "Current LR: [0.001]\n",
      "loss 0.34070688486099243\n",
      "Current LR: [0.001]\n",
      "loss 0.4004504382610321\n",
      "Current LR: [0.001]\n",
      "loss 0.28966522216796875\n",
      "Current LR: [0.001]\n",
      "loss 0.460318922996521\n",
      "[2,  140] average loss for these 10 batches of 64 images is: 0.361\n",
      "total loss for validation set is 0.401\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.1814139485359192\n",
      "Current LR: [0.001]\n",
      "loss 0.25818708539009094\n",
      "Current LR: [0.001]\n",
      "loss 0.36836057901382446\n",
      "Current LR: [0.001]\n",
      "loss 0.4360857605934143\n",
      "Current LR: [0.001]\n",
      "loss 0.2675968110561371\n",
      "Current LR: [0.001]\n",
      "loss 0.28599902987480164\n",
      "Current LR: [0.001]\n",
      "loss 0.3320350646972656\n",
      "Current LR: [0.001]\n",
      "loss 0.32030290365219116\n",
      "Current LR: [0.001]\n",
      "loss 0.3603269159793854\n",
      "Current LR: [0.001]\n",
      "loss 0.41695553064346313\n",
      "[2,  150] average loss for these 10 batches of 64 images is: 0.323\n",
      "total loss for validation set is 0.587\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2567457854747772\n",
      "Current LR: [0.001]\n",
      "loss 0.14079786837100983\n",
      "Current LR: [0.001]\n",
      "loss 0.21652553975582123\n",
      "Current LR: [0.001]\n",
      "loss 0.24198853969573975\n",
      "Current LR: [0.001]\n",
      "loss 0.31583574414253235\n",
      "Current LR: [0.001]\n",
      "loss 0.3724883496761322\n",
      "Current LR: [0.001]\n",
      "loss 0.25696077942848206\n",
      "Current LR: [0.001]\n",
      "loss 0.19833219051361084\n",
      "Current LR: [0.001]\n",
      "loss 0.5901305675506592\n",
      "Current LR: [0.001]\n",
      "loss 0.5410522222518921\n",
      "[2,  160] average loss for these 10 batches of 64 images is: 0.313\n",
      "total loss for validation set is 0.538\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.26556769013404846\n",
      "Current LR: [0.001]\n",
      "loss 0.3183061480522156\n",
      "Current LR: [0.001]\n",
      "loss 0.3230575621128082\n",
      "Current LR: [0.001]\n",
      "loss 0.26422905921936035\n",
      "Current LR: [0.001]\n",
      "loss 0.1751004159450531\n",
      "Current LR: [0.001]\n",
      "loss 0.2382153570652008\n",
      "Current LR: [0.001]\n",
      "loss 0.17670822143554688\n",
      "Current LR: [0.001]\n",
      "loss 0.25410398840904236\n",
      "Current LR: [0.001]\n",
      "loss 0.17022985219955444\n",
      "Current LR: [0.001]\n",
      "loss 0.3111862540245056\n",
      "Current LR: [0.001]\n",
      "loss 0.49307921528816223\n",
      "Current LR: [0.001]\n",
      "loss 0.18921545147895813\n",
      "Current LR: [0.001]\n",
      "loss 0.2447100281715393\n",
      "[3,   10] average loss for these 10 batches of 64 images is: 0.252\n",
      "total loss for validation set is 0.744\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3280295431613922\n",
      "Current LR: [0.001]\n",
      "loss 0.4033612906932831\n",
      "Current LR: [0.001]\n",
      "loss 0.25072523951530457\n",
      "Current LR: [0.001]\n",
      "loss 0.4009680151939392\n",
      "Current LR: [0.001]\n",
      "loss 0.28525590896606445\n",
      "Current LR: [0.001]\n",
      "loss 0.5446465611457825\n",
      "Current LR: [0.001]\n",
      "loss 0.35250309109687805\n",
      "Current LR: [0.001]\n",
      "loss 0.38547906279563904\n",
      "Current LR: [0.001]\n",
      "loss 0.23175765573978424\n",
      "Current LR: [0.001]\n",
      "loss 0.6232720613479614\n",
      "[3,   20] average loss for these 10 batches of 64 images is: 0.381\n",
      "total loss for validation set is 0.527\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.5406621694564819\n",
      "Current LR: [0.001]\n",
      "loss 0.32957974076271057\n",
      "Current LR: [0.001]\n",
      "loss 0.3587489724159241\n",
      "Current LR: [0.001]\n",
      "loss 0.2559334635734558\n",
      "Current LR: [0.001]\n",
      "loss 0.3420945107936859\n",
      "Current LR: [0.001]\n",
      "loss 0.25992658734321594\n",
      "Current LR: [0.001]\n",
      "loss 0.6120580434799194\n",
      "Current LR: [0.001]\n",
      "loss 0.17162266373634338\n",
      "Current LR: [0.001]\n",
      "loss 0.2513411045074463\n",
      "Current LR: [0.001]\n",
      "loss 0.47437602281570435\n",
      "[3,   30] average loss for these 10 batches of 64 images is: 0.360\n",
      "total loss for validation set is 0.576\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.20387308299541473\n",
      "Current LR: [0.001]\n",
      "loss 0.2493678629398346\n",
      "Current LR: [0.001]\n",
      "loss 0.5371261239051819\n",
      "Current LR: [0.001]\n",
      "loss 0.21873368322849274\n",
      "Current LR: [0.001]\n",
      "loss 0.45445114374160767\n",
      "Current LR: [0.001]\n",
      "loss 0.40481582283973694\n",
      "Current LR: [0.001]\n",
      "loss 0.3106367290019989\n",
      "Current LR: [0.001]\n",
      "loss 0.3396683931350708\n",
      "Current LR: [0.001]\n",
      "loss 0.4369966983795166\n",
      "Current LR: [0.001]\n",
      "loss 0.2735854983329773\n",
      "[3,   40] average loss for these 10 batches of 64 images is: 0.343\n",
      "total loss for validation set is 0.344\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3512536287307739\n",
      "Current LR: [0.001]\n",
      "loss 0.1768404245376587\n",
      "Current LR: [0.001]\n",
      "loss 0.21553727984428406\n",
      "Current LR: [0.001]\n",
      "loss 0.3399001657962799\n",
      "Current LR: [0.001]\n",
      "loss 0.2799953818321228\n",
      "Current LR: [0.001]\n",
      "loss 0.3266809582710266\n",
      "Current LR: [0.001]\n",
      "loss 0.3365093469619751\n",
      "Current LR: [0.001]\n",
      "loss 0.2276933640241623\n",
      "Current LR: [0.001]\n",
      "loss 0.3377343416213989\n",
      "Current LR: [0.001]\n",
      "loss 0.23981508612632751\n",
      "[3,   50] average loss for these 10 batches of 64 images is: 0.283\n",
      "total loss for validation set is 0.728\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3290553390979767\n",
      "Current LR: [0.001]\n",
      "loss 0.30482643842697144\n",
      "Current LR: [0.001]\n",
      "loss 0.13254320621490479\n",
      "Current LR: [0.001]\n",
      "loss 0.285127729177475\n",
      "Current LR: [0.001]\n",
      "loss 0.27602875232696533\n",
      "Current LR: [0.001]\n",
      "loss 0.3801080584526062\n",
      "Current LR: [0.001]\n",
      "loss 0.2692209780216217\n",
      "Current LR: [0.001]\n",
      "loss 0.3532390594482422\n",
      "Current LR: [0.001]\n",
      "loss 0.3805331587791443\n",
      "Current LR: [0.001]\n",
      "loss 0.2648729383945465\n",
      "[3,   60] average loss for these 10 batches of 64 images is: 0.298\n",
      "saving best model\n",
      "total loss for validation set is 0.296\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.27984264492988586\n",
      "Current LR: [0.001]\n",
      "loss 0.23354409635066986\n",
      "Current LR: [0.001]\n",
      "loss 0.16211377084255219\n",
      "Current LR: [0.001]\n",
      "loss 0.19969722628593445\n",
      "Current LR: [0.001]\n",
      "loss 0.22270207107067108\n",
      "Current LR: [0.001]\n",
      "loss 0.19866301119327545\n",
      "Current LR: [0.001]\n",
      "loss 0.2969352602958679\n",
      "Current LR: [0.001]\n",
      "loss 0.2684473395347595\n",
      "Current LR: [0.001]\n",
      "loss 0.2897774279117584\n",
      "Current LR: [0.001]\n",
      "loss 0.49512559175491333\n",
      "[3,   70] average loss for these 10 batches of 64 images is: 0.265\n",
      "total loss for validation set is 2.065\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.23125039041042328\n",
      "Current LR: [0.001]\n",
      "loss 0.245806023478508\n",
      "Current LR: [0.001]\n",
      "loss 0.6209323406219482\n",
      "Current LR: [0.001]\n",
      "loss 0.2994289696216583\n",
      "Current LR: [0.001]\n",
      "loss 0.16083472967147827\n",
      "Current LR: [0.001]\n",
      "loss 0.2896142601966858\n",
      "Current LR: [0.001]\n",
      "loss 0.3049759864807129\n",
      "Current LR: [0.001]\n",
      "loss 0.37322285771369934\n",
      "Current LR: [0.001]\n",
      "loss 0.42266392707824707\n",
      "Current LR: [0.001]\n",
      "loss 0.40448787808418274\n",
      "[3,   80] average loss for these 10 batches of 64 images is: 0.335\n",
      "total loss for validation set is 0.326\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.4277927279472351\n",
      "Current LR: [0.001]\n",
      "loss 0.7031226754188538\n",
      "Current LR: [0.001]\n",
      "loss 0.47397831082344055\n",
      "Current LR: [0.001]\n",
      "loss 0.210359588265419\n",
      "Current LR: [0.001]\n",
      "loss 0.2545025944709778\n",
      "Current LR: [0.001]\n",
      "loss 0.32133549451828003\n",
      "Current LR: [0.001]\n",
      "loss 0.32096248865127563\n",
      "Current LR: [0.001]\n",
      "loss 0.2807728946208954\n",
      "Current LR: [0.001]\n",
      "loss 0.31890085339546204\n",
      "Current LR: [0.001]\n",
      "loss 0.4277244806289673\n",
      "[3,   90] average loss for these 10 batches of 64 images is: 0.374\n",
      "total loss for validation set is 0.567\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3458225429058075\n",
      "Current LR: [0.001]\n",
      "loss 0.23350471258163452\n",
      "Current LR: [0.001]\n",
      "loss 0.3035672605037689\n",
      "Current LR: [0.001]\n",
      "loss 0.43345409631729126\n",
      "Current LR: [0.001]\n",
      "loss 0.2646799385547638\n",
      "Current LR: [0.001]\n",
      "loss 0.22016653418540955\n",
      "Current LR: [0.001]\n",
      "loss 0.30476611852645874\n",
      "Current LR: [0.001]\n",
      "loss 0.2109350860118866\n",
      "Current LR: [0.001]\n",
      "loss 0.3512818515300751\n",
      "Current LR: [0.001]\n",
      "loss 0.15099471807479858\n",
      "[3,  100] average loss for these 10 batches of 64 images is: 0.282\n",
      "total loss for validation set is 0.770\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.1697542518377304\n",
      "Current LR: [0.001]\n",
      "loss 0.2943896949291229\n",
      "Current LR: [0.001]\n",
      "loss 0.26721110939979553\n",
      "Current LR: [0.001]\n",
      "loss 0.23769806325435638\n",
      "Current LR: [0.001]\n",
      "loss 0.23668508231639862\n",
      "Current LR: [0.001]\n",
      "loss 0.24150943756103516\n",
      "Current LR: [0.001]\n",
      "loss 0.593351423740387\n",
      "Current LR: [0.001]\n",
      "loss 0.31182485818862915\n",
      "Current LR: [0.001]\n",
      "loss 0.22661274671554565\n",
      "Current LR: [0.001]\n",
      "loss 0.23308010399341583\n",
      "[3,  110] average loss for these 10 batches of 64 images is: 0.281\n",
      "total loss for validation set is 0.571\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2473667711019516\n",
      "Current LR: [0.001]\n",
      "loss 0.1930374652147293\n",
      "Current LR: [0.001]\n",
      "loss 0.41491302847862244\n",
      "Current LR: [0.001]\n",
      "loss 0.24540673196315765\n",
      "Current LR: [0.001]\n",
      "loss 0.14865347743034363\n",
      "Current LR: [0.001]\n",
      "loss 0.13480399549007416\n",
      "Current LR: [0.001]\n",
      "loss 0.19826479256153107\n",
      "Current LR: [0.001]\n",
      "loss 0.25219687819480896\n",
      "Current LR: [0.001]\n",
      "loss 0.31029272079467773\n",
      "Current LR: [0.001]\n",
      "loss 0.7413474321365356\n",
      "[3,  120] average loss for these 10 batches of 64 images is: 0.289\n",
      "total loss for validation set is 0.643\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.41650354862213135\n",
      "Current LR: [0.001]\n",
      "loss 0.23765505850315094\n",
      "Current LR: [0.001]\n",
      "loss 0.2506970465183258\n",
      "Current LR: [0.001]\n",
      "loss 0.2644079327583313\n",
      "Current LR: [0.001]\n",
      "loss 0.2202627956867218\n",
      "Current LR: [0.001]\n",
      "loss 0.3108052909374237\n",
      "Current LR: [0.001]\n",
      "loss 0.27940866351127625\n",
      "Current LR: [0.001]\n",
      "loss 0.37158870697021484\n",
      "Current LR: [0.001]\n",
      "loss 0.2749009132385254\n",
      "Current LR: [0.001]\n",
      "loss 0.18908533453941345\n",
      "[3,  130] average loss for these 10 batches of 64 images is: 0.282\n",
      "total loss for validation set is 0.787\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.13573157787322998\n",
      "Current LR: [0.001]\n",
      "loss 0.1557106375694275\n",
      "Current LR: [0.001]\n",
      "loss 0.19198931753635406\n",
      "Current LR: [0.001]\n",
      "loss 0.35214558243751526\n",
      "Current LR: [0.001]\n",
      "loss 0.3901541531085968\n",
      "Current LR: [0.001]\n",
      "loss 0.14960229396820068\n",
      "Current LR: [0.001]\n",
      "loss 0.4941873252391815\n",
      "Current LR: [0.001]\n",
      "loss 0.267092764377594\n",
      "Current LR: [0.001]\n",
      "loss 0.2600090801715851\n",
      "Current LR: [0.001]\n",
      "loss 0.1876499503850937\n",
      "[3,  140] average loss for these 10 batches of 64 images is: 0.258\n",
      "total loss for validation set is 0.769\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.41594818234443665\n",
      "Current LR: [0.001]\n",
      "loss 0.16073700785636902\n",
      "Current LR: [0.001]\n",
      "loss 0.22650133073329926\n",
      "Current LR: [0.001]\n",
      "loss 0.21372438967227936\n",
      "Current LR: [0.001]\n",
      "loss 0.3787635266780853\n",
      "Current LR: [0.001]\n",
      "loss 0.45207956433296204\n",
      "Current LR: [0.001]\n",
      "loss 0.30626749992370605\n",
      "Current LR: [0.001]\n",
      "loss 0.33166423439979553\n",
      "Current LR: [0.001]\n",
      "loss 0.3014189302921295\n",
      "Current LR: [0.001]\n",
      "loss 0.2221842259168625\n",
      "[3,  150] average loss for these 10 batches of 64 images is: 0.301\n",
      "total loss for validation set is 0.470\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.30240002274513245\n",
      "Current LR: [0.001]\n",
      "loss 0.21842214465141296\n",
      "Current LR: [0.001]\n",
      "loss 0.28154078125953674\n",
      "Current LR: [0.001]\n",
      "loss 0.29204076528549194\n",
      "Current LR: [0.001]\n",
      "loss 0.2920154631137848\n",
      "Current LR: [0.001]\n",
      "loss 0.3001057505607605\n",
      "Current LR: [0.001]\n",
      "loss 0.16627365350723267\n",
      "Current LR: [0.001]\n",
      "loss 0.2686347961425781\n",
      "Current LR: [0.001]\n",
      "loss 0.18814830482006073\n",
      "Current LR: [0.001]\n",
      "loss 0.5918296575546265\n",
      "[3,  160] average loss for these 10 batches of 64 images is: 0.290\n",
      "total loss for validation set is 1.016\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3738974928855896\n",
      "Current LR: [0.001]\n",
      "loss 0.24400240182876587\n",
      "Current LR: [0.001]\n",
      "loss 0.24173405766487122\n",
      "Current LR: [0.001]\n",
      "loss 0.19939717650413513\n",
      "Current LR: [0.001]\n",
      "loss 0.31825464963912964\n",
      "Current LR: [0.001]\n",
      "loss 0.3043784201145172\n",
      "Current LR: [0.001]\n",
      "loss 0.5670371055603027\n",
      "Current LR: [0.001]\n",
      "loss 0.1904602348804474\n",
      "Current LR: [0.001]\n",
      "loss 0.18991538882255554\n",
      "Current LR: [0.001]\n",
      "loss 0.4595385789871216\n",
      "Current LR: [0.001]\n",
      "loss 0.20703120529651642\n",
      "Current LR: [0.001]\n",
      "loss 0.5079439878463745\n",
      "Current LR: [0.001]\n",
      "loss 0.3302072286605835\n",
      "[4,   10] average loss for these 10 batches of 64 images is: 0.327\n",
      "total loss for validation set is 0.742\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2943674325942993\n",
      "Current LR: [0.001]\n",
      "loss 0.4861709177494049\n",
      "Current LR: [0.001]\n",
      "loss 0.18892470002174377\n",
      "Current LR: [0.001]\n",
      "loss 0.2724402844905853\n",
      "Current LR: [0.001]\n",
      "loss 0.2117539942264557\n",
      "Current LR: [0.001]\n",
      "loss 0.4228317141532898\n",
      "Current LR: [0.001]\n",
      "loss 0.3430146276950836\n",
      "Current LR: [0.001]\n",
      "loss 0.238508403301239\n",
      "Current LR: [0.001]\n",
      "loss 0.3015616536140442\n",
      "Current LR: [0.001]\n",
      "loss 0.23778709769248962\n",
      "[4,   20] average loss for these 10 batches of 64 images is: 0.300\n",
      "total loss for validation set is 1.003\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.43776383996009827\n",
      "Current LR: [0.001]\n",
      "loss 0.33580976724624634\n",
      "Current LR: [0.001]\n",
      "loss 0.20842307806015015\n",
      "Current LR: [0.001]\n",
      "loss 0.5590394139289856\n",
      "Current LR: [0.001]\n",
      "loss 0.2911718189716339\n",
      "Current LR: [0.001]\n",
      "loss 0.4141884744167328\n",
      "Current LR: [0.001]\n",
      "loss 0.2315111756324768\n",
      "Current LR: [0.001]\n",
      "loss 0.2591630816459656\n",
      "Current LR: [0.001]\n",
      "loss 0.3809133768081665\n",
      "Current LR: [0.001]\n",
      "loss 0.20736822485923767\n",
      "[4,   30] average loss for these 10 batches of 64 images is: 0.333\n",
      "total loss for validation set is 0.584\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.19522607326507568\n",
      "Current LR: [0.001]\n",
      "loss 0.42229247093200684\n",
      "Current LR: [0.001]\n",
      "loss 0.24765193462371826\n",
      "Current LR: [0.001]\n",
      "loss 0.2777538597583771\n",
      "Current LR: [0.001]\n",
      "loss 0.2933465242385864\n",
      "Current LR: [0.001]\n",
      "loss 0.13070134818553925\n",
      "Current LR: [0.001]\n",
      "loss 0.31406593322753906\n",
      "Current LR: [0.001]\n",
      "loss 0.3656565546989441\n",
      "Current LR: [0.001]\n",
      "loss 0.16398167610168457\n",
      "Current LR: [0.001]\n",
      "loss 0.15247705578804016\n",
      "[4,   40] average loss for these 10 batches of 64 images is: 0.256\n",
      "total loss for validation set is 0.555\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.15699447691440582\n",
      "Current LR: [0.001]\n",
      "loss 0.23099543154239655\n",
      "Current LR: [0.001]\n",
      "loss 0.553067147731781\n",
      "Current LR: [0.001]\n",
      "loss 0.14887911081314087\n",
      "Current LR: [0.001]\n",
      "loss 0.15728531777858734\n",
      "Current LR: [0.001]\n",
      "loss 0.40904197096824646\n",
      "Current LR: [0.001]\n",
      "loss 0.25804710388183594\n",
      "Current LR: [0.001]\n",
      "loss 0.14064118266105652\n",
      "Current LR: [0.001]\n",
      "loss 0.10915955901145935\n",
      "Current LR: [0.001]\n",
      "loss 0.28391528129577637\n",
      "[4,   50] average loss for these 10 batches of 64 images is: 0.245\n",
      "total loss for validation set is 0.918\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.18643617630004883\n",
      "Current LR: [0.001]\n",
      "loss 0.3413959741592407\n",
      "Current LR: [0.001]\n",
      "loss 0.17002785205841064\n",
      "Current LR: [0.001]\n",
      "loss 0.1549271047115326\n",
      "Current LR: [0.001]\n",
      "loss 0.19646131992340088\n",
      "Current LR: [0.001]\n",
      "loss 0.23522470891475677\n",
      "Current LR: [0.001]\n",
      "loss 0.2732555866241455\n",
      "Current LR: [0.001]\n",
      "loss 0.21843436360359192\n",
      "Current LR: [0.001]\n",
      "loss 0.3724609613418579\n",
      "Current LR: [0.001]\n",
      "loss 0.07056541740894318\n",
      "[4,   60] average loss for these 10 batches of 64 images is: 0.222\n",
      "total loss for validation set is 0.526\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2681007981300354\n",
      "Current LR: [0.001]\n",
      "loss 0.13234059512615204\n",
      "Current LR: [0.001]\n",
      "loss 0.31530529260635376\n",
      "Current LR: [0.001]\n",
      "loss 0.10264170169830322\n",
      "Current LR: [0.001]\n",
      "loss 0.2525978684425354\n",
      "Current LR: [0.001]\n",
      "loss 0.2161264419555664\n",
      "Current LR: [0.001]\n",
      "loss 0.13383258879184723\n",
      "Current LR: [0.001]\n",
      "loss 0.44626545906066895\n",
      "Current LR: [0.001]\n",
      "loss 0.28739383816719055\n",
      "Current LR: [0.001]\n",
      "loss 0.30033165216445923\n",
      "[4,   70] average loss for these 10 batches of 64 images is: 0.245\n",
      "total loss for validation set is 0.622\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.24929013848304749\n",
      "Current LR: [0.001]\n",
      "loss 0.26235777139663696\n",
      "Current LR: [0.001]\n",
      "loss 0.26907968521118164\n",
      "Current LR: [0.001]\n",
      "loss 0.1876986026763916\n",
      "Current LR: [0.001]\n",
      "loss 0.20159003138542175\n",
      "Current LR: [0.001]\n",
      "loss 0.2049296796321869\n",
      "Current LR: [0.001]\n",
      "loss 0.44705861806869507\n",
      "Current LR: [0.001]\n",
      "loss 0.33515921235084534\n",
      "Current LR: [0.001]\n",
      "loss 0.4480626583099365\n",
      "Current LR: [0.001]\n",
      "loss 0.3556616008281708\n",
      "[4,   80] average loss for these 10 batches of 64 images is: 0.296\n",
      "total loss for validation set is 0.742\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.30767717957496643\n",
      "Current LR: [0.001]\n",
      "loss 0.17162679135799408\n",
      "Current LR: [0.001]\n",
      "loss 0.2684164047241211\n",
      "Current LR: [0.001]\n",
      "loss 0.25706595182418823\n",
      "Current LR: [0.001]\n",
      "loss 0.3293343782424927\n",
      "Current LR: [0.001]\n",
      "loss 0.32444921135902405\n",
      "Current LR: [0.001]\n",
      "loss 0.20712445676326752\n",
      "Current LR: [0.001]\n",
      "loss 0.40804681181907654\n",
      "Current LR: [0.001]\n",
      "loss 0.24580951035022736\n",
      "Current LR: [0.001]\n",
      "loss 0.4202994406223297\n",
      "[4,   90] average loss for these 10 batches of 64 images is: 0.294\n",
      "total loss for validation set is 0.843\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.271772176027298\n",
      "Current LR: [0.001]\n",
      "loss 0.2252849042415619\n",
      "Current LR: [0.001]\n",
      "loss 0.41489872336387634\n",
      "Current LR: [0.001]\n",
      "loss 0.2158030867576599\n",
      "Current LR: [0.001]\n",
      "loss 0.30192831158638\n",
      "Current LR: [0.001]\n",
      "loss 0.5039563179016113\n",
      "Current LR: [0.001]\n",
      "loss 0.4742814600467682\n",
      "Current LR: [0.001]\n",
      "loss 0.39341995120048523\n",
      "Current LR: [0.001]\n",
      "loss 0.2989179491996765\n",
      "Current LR: [0.001]\n",
      "loss 0.47552087903022766\n",
      "[4,  100] average loss for these 10 batches of 64 images is: 0.358\n",
      "saving best model\n",
      "total loss for validation set is 0.256\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.34602248668670654\n",
      "Current LR: [0.001]\n",
      "loss 0.3602113127708435\n",
      "Current LR: [0.001]\n",
      "loss 0.23230691254138947\n",
      "Current LR: [0.001]\n",
      "loss 0.25302594900131226\n",
      "Current LR: [0.001]\n",
      "loss 0.3728938102722168\n",
      "Current LR: [0.001]\n",
      "loss 0.2526562809944153\n",
      "Current LR: [0.001]\n",
      "loss 0.2568971514701843\n",
      "Current LR: [0.001]\n",
      "loss 0.19236204028129578\n",
      "Current LR: [0.001]\n",
      "loss 0.46545785665512085\n",
      "Current LR: [0.001]\n",
      "loss 0.19032908976078033\n",
      "[4,  110] average loss for these 10 batches of 64 images is: 0.292\n",
      "total loss for validation set is 0.344\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.25373271107673645\n",
      "Current LR: [0.001]\n",
      "loss 0.3141549229621887\n",
      "Current LR: [0.001]\n",
      "loss 0.1620122492313385\n",
      "Current LR: [0.001]\n",
      "loss 0.20977823436260223\n",
      "Current LR: [0.001]\n",
      "loss 0.44890719652175903\n",
      "Current LR: [0.001]\n",
      "loss 0.35248416662216187\n",
      "Current LR: [0.001]\n",
      "loss 0.24038437008857727\n",
      "Current LR: [0.001]\n",
      "loss 0.1492295116186142\n",
      "Current LR: [0.001]\n",
      "loss 0.19034284353256226\n",
      "Current LR: [0.001]\n",
      "loss 0.17868442833423615\n",
      "[4,  120] average loss for these 10 batches of 64 images is: 0.250\n",
      "total loss for validation set is 0.750\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2520688474178314\n",
      "Current LR: [0.001]\n",
      "loss 0.37226602435112\n",
      "Current LR: [0.001]\n",
      "loss 0.1725948601961136\n",
      "Current LR: [0.001]\n",
      "loss 0.23358148336410522\n",
      "Current LR: [0.001]\n",
      "loss 0.33283066749572754\n",
      "Current LR: [0.001]\n",
      "loss 0.3756484389305115\n",
      "Current LR: [0.001]\n",
      "loss 0.31910961866378784\n",
      "Current LR: [0.001]\n",
      "loss 0.21474990248680115\n",
      "Current LR: [0.001]\n",
      "loss 0.3087412416934967\n",
      "Current LR: [0.001]\n",
      "loss 0.21962259709835052\n",
      "[4,  130] average loss for these 10 batches of 64 images is: 0.280\n",
      "total loss for validation set is 1.137\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.18181581795215607\n",
      "Current LR: [0.001]\n",
      "loss 0.2490258663892746\n",
      "Current LR: [0.001]\n",
      "loss 0.3115657567977905\n",
      "Current LR: [0.001]\n",
      "loss 0.28395938873291016\n",
      "Current LR: [0.001]\n",
      "loss 0.4263398051261902\n",
      "Current LR: [0.001]\n",
      "loss 0.27607375383377075\n",
      "Current LR: [0.001]\n",
      "loss 0.33782392740249634\n",
      "Current LR: [0.001]\n",
      "loss 0.24411121010780334\n",
      "Current LR: [0.001]\n",
      "loss 0.3163422644138336\n",
      "Current LR: [0.001]\n",
      "loss 0.1350954920053482\n",
      "[4,  140] average loss for these 10 batches of 64 images is: 0.276\n",
      "total loss for validation set is 0.499\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2673192322254181\n",
      "Current LR: [0.001]\n",
      "loss 0.23133066296577454\n",
      "Current LR: [0.001]\n",
      "loss 0.35876595973968506\n",
      "Current LR: [0.001]\n",
      "loss 0.2992643713951111\n",
      "Current LR: [0.001]\n",
      "loss 0.2900773584842682\n",
      "Current LR: [0.001]\n",
      "loss 0.2346673458814621\n",
      "Current LR: [0.001]\n",
      "loss 0.19076186418533325\n",
      "Current LR: [0.001]\n",
      "loss 0.20662538707256317\n",
      "Current LR: [0.001]\n",
      "loss 0.2937757670879364\n",
      "Current LR: [0.001]\n",
      "loss 0.2538534998893738\n",
      "[4,  150] average loss for these 10 batches of 64 images is: 0.263\n",
      "total loss for validation set is 0.651\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.29309338331222534\n",
      "Current LR: [0.001]\n",
      "loss 0.3018043041229248\n",
      "Current LR: [0.001]\n",
      "loss 0.3892327547073364\n",
      "Current LR: [0.001]\n",
      "loss 0.2598300576210022\n",
      "Current LR: [0.001]\n",
      "loss 0.3048052191734314\n",
      "Current LR: [0.001]\n",
      "loss 0.20792622864246368\n",
      "Current LR: [0.001]\n",
      "loss 0.2436496466398239\n",
      "Current LR: [0.001]\n",
      "loss 0.1745496392250061\n",
      "Current LR: [0.001]\n",
      "loss 0.16417507827281952\n",
      "Current LR: [0.001]\n",
      "loss 0.28143173456192017\n",
      "[4,  160] average loss for these 10 batches of 64 images is: 0.262\n",
      "total loss for validation set is 1.001\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2989533245563507\n",
      "Current LR: [0.001]\n",
      "loss 0.19005471467971802\n",
      "Current LR: [0.001]\n",
      "loss 0.13587160408496857\n",
      "Current LR: [0.001]\n",
      "loss 0.16156981885433197\n",
      "Current LR: [0.001]\n",
      "loss 0.26718398928642273\n",
      "Current LR: [0.001]\n",
      "loss 0.2683849036693573\n",
      "Current LR: [0.001]\n",
      "loss 0.1365598887205124\n",
      "Current LR: [0.001]\n",
      "loss 0.26616305112838745\n",
      "Current LR: [0.001]\n",
      "loss 0.19150695204734802\n",
      "Current LR: [0.001]\n",
      "loss 0.3435988426208496\n",
      "Current LR: [0.001]\n",
      "loss 0.2555687725543976\n",
      "Current LR: [0.001]\n",
      "loss 0.34883806109428406\n",
      "Current LR: [0.001]\n",
      "loss 0.21826422214508057\n",
      "[5,   10] average loss for these 10 batches of 64 images is: 0.246\n",
      "total loss for validation set is 1.085\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.15556147694587708\n",
      "Current LR: [0.001]\n",
      "loss 0.21138574182987213\n",
      "Current LR: [0.001]\n",
      "loss 0.19177772104740143\n",
      "Current LR: [0.001]\n",
      "loss 0.2379804402589798\n",
      "Current LR: [0.001]\n",
      "loss 0.17503128945827484\n",
      "Current LR: [0.001]\n",
      "loss 0.18075913190841675\n",
      "Current LR: [0.001]\n",
      "loss 0.3434349596500397\n",
      "Current LR: [0.001]\n",
      "loss 0.2844295799732208\n",
      "Current LR: [0.001]\n",
      "loss 0.2133278250694275\n",
      "Current LR: [0.001]\n",
      "loss 0.40072333812713623\n",
      "[5,   20] average loss for these 10 batches of 64 images is: 0.239\n",
      "total loss for validation set is 0.362\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3116762340068817\n",
      "Current LR: [0.001]\n",
      "loss 0.17940764129161835\n",
      "Current LR: [0.001]\n",
      "loss 0.11236858367919922\n",
      "Current LR: [0.001]\n",
      "loss 0.448637992143631\n",
      "Current LR: [0.001]\n",
      "loss 0.36890870332717896\n",
      "Current LR: [0.001]\n",
      "loss 0.36016058921813965\n",
      "Current LR: [0.001]\n",
      "loss 0.3174390196800232\n",
      "Current LR: [0.001]\n",
      "loss 0.16793787479400635\n",
      "Current LR: [0.001]\n",
      "loss 0.3597244322299957\n",
      "Current LR: [0.001]\n",
      "loss 0.2747543156147003\n",
      "[5,   30] average loss for these 10 batches of 64 images is: 0.290\n",
      "total loss for validation set is 0.300\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.24892018735408783\n",
      "Current LR: [0.001]\n",
      "loss 0.23062185943126678\n",
      "Current LR: [0.001]\n",
      "loss 0.15699051320552826\n",
      "Current LR: [0.001]\n",
      "loss 0.26434263586997986\n",
      "Current LR: [0.001]\n",
      "loss 0.25706231594085693\n",
      "Current LR: [0.001]\n",
      "loss 0.20708739757537842\n",
      "Current LR: [0.001]\n",
      "loss 0.18948908150196075\n",
      "Current LR: [0.001]\n",
      "loss 0.2684016525745392\n",
      "Current LR: [0.001]\n",
      "loss 0.2592052221298218\n",
      "Current LR: [0.001]\n",
      "loss 0.21423257887363434\n",
      "[5,   40] average loss for these 10 batches of 64 images is: 0.230\n",
      "total loss for validation set is 0.742\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2634250819683075\n",
      "Current LR: [0.001]\n",
      "loss 0.20450080931186676\n",
      "Current LR: [0.001]\n",
      "loss 0.3633393943309784\n",
      "Current LR: [0.001]\n",
      "loss 0.30321571230888367\n",
      "Current LR: [0.001]\n",
      "loss 0.16179320216178894\n",
      "Current LR: [0.001]\n",
      "loss 0.23191876709461212\n",
      "Current LR: [0.001]\n",
      "loss 0.3069099187850952\n",
      "Current LR: [0.001]\n",
      "loss 0.20436663925647736\n",
      "Current LR: [0.001]\n",
      "loss 0.28252750635147095\n",
      "Current LR: [0.001]\n",
      "loss 0.26694822311401367\n",
      "[5,   50] average loss for these 10 batches of 64 images is: 0.259\n",
      "total loss for validation set is 1.161\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.41234248876571655\n",
      "Current LR: [0.001]\n",
      "loss 0.14998821914196014\n",
      "Current LR: [0.001]\n",
      "loss 0.3084747791290283\n",
      "Current LR: [0.001]\n",
      "loss 0.27045154571533203\n",
      "Current LR: [0.001]\n",
      "loss 0.23552048206329346\n",
      "Current LR: [0.001]\n",
      "loss 0.2016676515340805\n",
      "Current LR: [0.001]\n",
      "loss 0.1843201071023941\n",
      "Current LR: [0.001]\n",
      "loss 0.28649264574050903\n",
      "Current LR: [0.001]\n",
      "loss 0.2622140347957611\n",
      "Current LR: [0.001]\n",
      "loss 0.435146301984787\n",
      "[5,   60] average loss for these 10 batches of 64 images is: 0.275\n",
      "total loss for validation set is 0.678\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.38006237149238586\n",
      "Current LR: [0.001]\n",
      "loss 0.4001926779747009\n",
      "Current LR: [0.001]\n",
      "loss 0.21833249926567078\n",
      "Current LR: [0.001]\n",
      "loss 0.20351245999336243\n",
      "Current LR: [0.001]\n",
      "loss 0.30046892166137695\n",
      "Current LR: [0.001]\n",
      "loss 0.18712152540683746\n",
      "Current LR: [0.001]\n",
      "loss 0.21577951312065125\n",
      "Current LR: [0.001]\n",
      "loss 0.2524491250514984\n",
      "Current LR: [0.001]\n",
      "loss 0.16183090209960938\n",
      "Current LR: [0.001]\n",
      "loss 0.417840838432312\n",
      "[5,   70] average loss for these 10 batches of 64 images is: 0.274\n",
      "total loss for validation set is 0.486\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.20410794019699097\n",
      "Current LR: [0.001]\n",
      "loss 0.2404317706823349\n",
      "Current LR: [0.001]\n",
      "loss 0.31914713978767395\n",
      "Current LR: [0.001]\n",
      "loss 0.11744674295186996\n",
      "Current LR: [0.001]\n",
      "loss 0.379722535610199\n",
      "Current LR: [0.001]\n",
      "loss 0.27166712284088135\n",
      "Current LR: [0.001]\n",
      "loss 0.48468074202537537\n",
      "Current LR: [0.001]\n",
      "loss 0.5609957575798035\n",
      "Current LR: [0.001]\n",
      "loss 0.2697755694389343\n",
      "Current LR: [0.001]\n",
      "loss 0.15687307715415955\n",
      "[5,   80] average loss for these 10 batches of 64 images is: 0.300\n",
      "total loss for validation set is 0.420\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.27767059206962585\n",
      "Current LR: [0.001]\n",
      "loss 0.21485519409179688\n",
      "Current LR: [0.001]\n",
      "loss 0.28773635625839233\n",
      "Current LR: [0.001]\n",
      "loss 0.3076127767562866\n",
      "Current LR: [0.001]\n",
      "loss 0.3493206202983856\n",
      "Current LR: [0.001]\n",
      "loss 0.34912222623825073\n",
      "Current LR: [0.001]\n",
      "loss 0.2569288909435272\n",
      "Current LR: [0.001]\n",
      "loss 0.19783765077590942\n",
      "Current LR: [0.001]\n",
      "loss 0.2321784943342209\n",
      "Current LR: [0.001]\n",
      "loss 0.3664431869983673\n",
      "[5,   90] average loss for these 10 batches of 64 images is: 0.284\n",
      "total loss for validation set is 0.345\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.153647780418396\n",
      "Current LR: [0.001]\n",
      "loss 0.28278642892837524\n",
      "Current LR: [0.001]\n",
      "loss 0.19363553822040558\n",
      "Current LR: [0.001]\n",
      "loss 0.1942521631717682\n",
      "Current LR: [0.001]\n",
      "loss 0.29192444682121277\n",
      "Current LR: [0.001]\n",
      "loss 0.3687991499900818\n",
      "Current LR: [0.001]\n",
      "loss 0.38094979524612427\n",
      "Current LR: [0.001]\n",
      "loss 0.4322342276573181\n",
      "Current LR: [0.001]\n",
      "loss 0.2099943608045578\n",
      "Current LR: [0.001]\n",
      "loss 0.3067410886287689\n",
      "[5,  100] average loss for these 10 batches of 64 images is: 0.281\n",
      "total loss for validation set is 0.984\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.23334729671478271\n",
      "Current LR: [0.001]\n",
      "loss 0.25196343660354614\n",
      "Current LR: [0.001]\n",
      "loss 0.2228114753961563\n",
      "Current LR: [0.001]\n",
      "loss 0.22781507670879364\n",
      "Current LR: [0.001]\n",
      "loss 0.13938069343566895\n",
      "Current LR: [0.001]\n",
      "loss 0.2206481397151947\n",
      "Current LR: [0.001]\n",
      "loss 0.09597636014223099\n",
      "Current LR: [0.001]\n",
      "loss 0.4821583032608032\n",
      "Current LR: [0.001]\n",
      "loss 0.26262804865837097\n",
      "Current LR: [0.001]\n",
      "loss 0.16957038640975952\n",
      "[5,  110] average loss for these 10 batches of 64 images is: 0.231\n",
      "total loss for validation set is 0.358\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.41183969378471375\n",
      "Current LR: [0.001]\n",
      "loss 0.18273673951625824\n",
      "Current LR: [0.001]\n",
      "loss 0.2842431962490082\n",
      "Current LR: [0.001]\n",
      "loss 0.17241114377975464\n",
      "Current LR: [0.001]\n",
      "loss 0.20808415114879608\n",
      "Current LR: [0.001]\n",
      "loss 0.5283569097518921\n",
      "Current LR: [0.001]\n",
      "loss 0.21965372562408447\n",
      "Current LR: [0.001]\n",
      "loss 0.3615383505821228\n",
      "Current LR: [0.001]\n",
      "loss 0.2150706946849823\n",
      "Current LR: [0.001]\n",
      "loss 0.3393305242061615\n",
      "[5,  120] average loss for these 10 batches of 64 images is: 0.292\n",
      "total loss for validation set is 0.274\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2877085208892822\n",
      "Current LR: [0.001]\n",
      "loss 0.2865138649940491\n",
      "Current LR: [0.001]\n",
      "loss 0.35337573289871216\n",
      "Current LR: [0.001]\n",
      "loss 0.5782699584960938\n",
      "Current LR: [0.001]\n",
      "loss 0.37454110383987427\n",
      "Current LR: [0.001]\n",
      "loss 0.1954449713230133\n",
      "Current LR: [0.001]\n",
      "loss 0.10962188243865967\n",
      "Current LR: [0.001]\n",
      "loss 0.5139222741127014\n",
      "Current LR: [0.001]\n",
      "loss 0.25468364357948303\n",
      "Current LR: [0.001]\n",
      "loss 0.4944528341293335\n",
      "[5,  130] average loss for these 10 batches of 64 images is: 0.345\n",
      "total loss for validation set is 0.545\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.30697599053382874\n",
      "Current LR: [0.001]\n",
      "loss 0.34302887320518494\n",
      "Current LR: [0.001]\n",
      "loss 0.21127113699913025\n",
      "Current LR: [0.001]\n",
      "loss 0.18193571269512177\n",
      "Current LR: [0.001]\n",
      "loss 0.3389992415904999\n",
      "Current LR: [0.001]\n",
      "loss 0.25968122482299805\n",
      "Current LR: [0.001]\n",
      "loss 0.2484193593263626\n",
      "Current LR: [0.001]\n",
      "loss 0.1812056452035904\n",
      "Current LR: [0.001]\n",
      "loss 0.2865026891231537\n",
      "Current LR: [0.001]\n",
      "loss 0.19552163779735565\n",
      "[5,  140] average loss for these 10 batches of 64 images is: 0.255\n",
      "total loss for validation set is 1.278\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2575145959854126\n",
      "Current LR: [0.001]\n",
      "loss 0.3543015718460083\n",
      "Current LR: [0.001]\n",
      "loss 0.3492773175239563\n",
      "Current LR: [0.001]\n",
      "loss 0.1939881294965744\n",
      "Current LR: [0.001]\n",
      "loss 0.2542312741279602\n",
      "Current LR: [0.001]\n",
      "loss 0.24245527386665344\n",
      "Current LR: [0.001]\n",
      "loss 0.24466802179813385\n",
      "Current LR: [0.001]\n",
      "loss 0.30995187163352966\n",
      "Current LR: [0.001]\n",
      "loss 0.2095593810081482\n",
      "Current LR: [0.001]\n",
      "loss 0.4143102467060089\n",
      "[5,  150] average loss for these 10 batches of 64 images is: 0.283\n",
      "total loss for validation set is 0.647\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.17759813368320465\n",
      "Current LR: [0.001]\n",
      "loss 0.34205007553100586\n",
      "Current LR: [0.001]\n",
      "loss 0.20810577273368835\n",
      "Current LR: [0.001]\n",
      "loss 0.2597385346889496\n",
      "Current LR: [0.001]\n",
      "loss 0.2587779760360718\n",
      "Current LR: [0.001]\n",
      "loss 0.3507440388202667\n",
      "Current LR: [0.001]\n",
      "loss 0.25878235697746277\n",
      "Current LR: [0.001]\n",
      "loss 0.12006696313619614\n",
      "Current LR: [0.001]\n",
      "loss 0.30448341369628906\n",
      "Current LR: [0.001]\n",
      "loss 0.17229607701301575\n",
      "[5,  160] average loss for these 10 batches of 64 images is: 0.245\n",
      "total loss for validation set is 1.036\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3967956602573395\n",
      "Current LR: [0.001]\n",
      "loss 0.19913895428180695\n",
      "Current LR: [0.001]\n",
      "loss 0.18912319839000702\n",
      "Current LR: [0.001]\n",
      "loss 0.14932548999786377\n",
      "Current LR: [0.001]\n",
      "loss 0.14889129996299744\n",
      "Current LR: [0.001]\n",
      "loss 0.09437012672424316\n",
      "Current LR: [0.001]\n",
      "loss 0.45884978771209717\n",
      "Current LR: [0.001]\n",
      "loss 0.212441548705101\n",
      "Current LR: [0.001]\n",
      "loss 0.19457675516605377\n",
      "Current LR: [0.001]\n",
      "loss 0.23076732456684113\n",
      "Current LR: [0.001]\n",
      "loss 0.315457284450531\n",
      "Current LR: [0.001]\n",
      "loss 0.49081864953041077\n",
      "Current LR: [0.001]\n",
      "loss 0.1087740957736969\n",
      "[6,   10] average loss for these 10 batches of 64 images is: 0.240\n",
      "total loss for validation set is 0.792\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.17780537903308868\n",
      "Current LR: [0.001]\n",
      "loss 0.2565973997116089\n",
      "Current LR: [0.001]\n",
      "loss 0.5187827944755554\n",
      "Current LR: [0.001]\n",
      "loss 0.49299687147140503\n",
      "Current LR: [0.001]\n",
      "loss 0.22343657910823822\n",
      "Current LR: [0.001]\n",
      "loss 0.20827776193618774\n",
      "Current LR: [0.001]\n",
      "loss 0.26081228256225586\n",
      "Current LR: [0.001]\n",
      "loss 0.2713460326194763\n",
      "Current LR: [0.001]\n",
      "loss 0.25993263721466064\n",
      "Current LR: [0.001]\n",
      "loss 0.14563001692295074\n",
      "[6,   20] average loss for these 10 batches of 64 images is: 0.282\n",
      "total loss for validation set is 0.327\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.24937576055526733\n",
      "Current LR: [0.001]\n",
      "loss 0.32530665397644043\n",
      "Current LR: [0.001]\n",
      "loss 0.29372018575668335\n",
      "Current LR: [0.001]\n",
      "loss 0.3181335926055908\n",
      "Current LR: [0.001]\n",
      "loss 0.39090532064437866\n",
      "Current LR: [0.001]\n",
      "loss 0.3398418128490448\n",
      "Current LR: [0.001]\n",
      "loss 0.20685556530952454\n",
      "Current LR: [0.001]\n",
      "loss 0.36031264066696167\n",
      "Current LR: [0.001]\n",
      "loss 0.2501584589481354\n",
      "Current LR: [0.001]\n",
      "loss 0.20809771120548248\n",
      "[6,   30] average loss for these 10 batches of 64 images is: 0.294\n",
      "total loss for validation set is 0.582\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2126685529947281\n",
      "Current LR: [0.001]\n",
      "loss 0.23542334139347076\n",
      "Current LR: [0.001]\n",
      "loss 0.20666848123073578\n",
      "Current LR: [0.001]\n",
      "loss 0.1392785906791687\n",
      "Current LR: [0.001]\n",
      "loss 0.30184993147850037\n",
      "Current LR: [0.001]\n",
      "loss 0.43145209550857544\n",
      "Current LR: [0.001]\n",
      "loss 0.4620903730392456\n",
      "Current LR: [0.001]\n",
      "loss 0.2762615978717804\n",
      "Current LR: [0.001]\n",
      "loss 0.36358708143234253\n",
      "Current LR: [0.001]\n",
      "loss 0.2907690107822418\n",
      "[6,   40] average loss for these 10 batches of 64 images is: 0.292\n",
      "total loss for validation set is 0.844\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.25720563530921936\n",
      "Current LR: [0.001]\n",
      "loss 0.2510097920894623\n",
      "Current LR: [0.001]\n",
      "loss 0.22879119217395782\n",
      "Current LR: [0.001]\n",
      "loss 0.3312508761882782\n",
      "Current LR: [0.001]\n",
      "loss 0.3473489284515381\n",
      "Current LR: [0.001]\n",
      "loss 0.19328629970550537\n",
      "Current LR: [0.001]\n",
      "loss 0.20913441479206085\n",
      "Current LR: [0.001]\n",
      "loss 0.35644933581352234\n",
      "Current LR: [0.001]\n",
      "loss 0.25896215438842773\n",
      "Current LR: [0.001]\n",
      "loss 0.41978293657302856\n",
      "[6,   50] average loss for these 10 batches of 64 images is: 0.285\n",
      "total loss for validation set is 0.592\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3112311363220215\n",
      "Current LR: [0.001]\n",
      "loss 0.19682930409908295\n",
      "Current LR: [0.001]\n",
      "loss 0.39764562249183655\n",
      "Current LR: [0.001]\n",
      "loss 0.19959600269794464\n",
      "Current LR: [0.001]\n",
      "loss 0.314772367477417\n",
      "Current LR: [0.001]\n",
      "loss 0.2473423331975937\n",
      "Current LR: [0.001]\n",
      "loss 0.1983523815870285\n",
      "Current LR: [0.001]\n",
      "loss 0.21611368656158447\n",
      "Current LR: [0.001]\n",
      "loss 0.2468131184577942\n",
      "Current LR: [0.001]\n",
      "loss 0.16830924153327942\n",
      "[6,   60] average loss for these 10 batches of 64 images is: 0.250\n",
      "total loss for validation set is 0.328\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.18749499320983887\n",
      "Current LR: [0.001]\n",
      "loss 0.260111004114151\n",
      "Current LR: [0.001]\n",
      "loss 0.20182478427886963\n",
      "Current LR: [0.001]\n",
      "loss 0.39601296186447144\n",
      "Current LR: [0.001]\n",
      "loss 0.5308302640914917\n",
      "Current LR: [0.001]\n",
      "loss 0.2638467848300934\n",
      "Current LR: [0.001]\n",
      "loss 0.23888757824897766\n",
      "Current LR: [0.001]\n",
      "loss 0.24248580634593964\n",
      "Current LR: [0.001]\n",
      "loss 0.18588438630104065\n",
      "Current LR: [0.001]\n",
      "loss 0.24128678441047668\n",
      "[6,   70] average loss for these 10 batches of 64 images is: 0.275\n",
      "total loss for validation set is 0.455\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.329130619764328\n",
      "Current LR: [0.001]\n",
      "loss 0.11051208525896072\n",
      "Current LR: [0.001]\n",
      "loss 0.244087815284729\n",
      "Current LR: [0.001]\n",
      "loss 0.24859891831874847\n",
      "Current LR: [0.001]\n",
      "loss 0.16044136881828308\n",
      "Current LR: [0.001]\n",
      "loss 0.2466588318347931\n",
      "Current LR: [0.001]\n",
      "loss 0.2275662124156952\n",
      "Current LR: [0.001]\n",
      "loss 0.26683592796325684\n",
      "Current LR: [0.001]\n",
      "loss 0.18847842514514923\n",
      "Current LR: [0.001]\n",
      "loss 0.36134812235832214\n",
      "[6,   80] average loss for these 10 batches of 64 images is: 0.238\n",
      "total loss for validation set is 1.423\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.19497977197170258\n",
      "Current LR: [0.001]\n",
      "loss 0.17907391488552094\n",
      "Current LR: [0.001]\n",
      "loss 0.23411133885383606\n",
      "Current LR: [0.001]\n",
      "loss 0.22574061155319214\n",
      "Current LR: [0.001]\n",
      "loss 0.3704448342323303\n",
      "Current LR: [0.001]\n",
      "loss 0.2111198902130127\n",
      "Current LR: [0.001]\n",
      "loss 0.3720535337924957\n",
      "Current LR: [0.001]\n",
      "loss 0.21208375692367554\n",
      "Current LR: [0.001]\n",
      "loss 0.2896200120449066\n",
      "Current LR: [0.001]\n",
      "loss 0.23240926861763\n",
      "[6,   90] average loss for these 10 batches of 64 images is: 0.252\n",
      "total loss for validation set is 0.456\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.12692341208457947\n",
      "Current LR: [0.001]\n",
      "loss 0.2035047858953476\n",
      "Current LR: [0.001]\n",
      "loss 0.4228920638561249\n",
      "Current LR: [0.001]\n",
      "loss 0.5474793910980225\n",
      "Current LR: [0.001]\n",
      "loss 0.18194639682769775\n",
      "Current LR: [0.001]\n",
      "loss 0.26019415259361267\n",
      "Current LR: [0.001]\n",
      "loss 0.3370315134525299\n",
      "Current LR: [0.001]\n",
      "loss 0.19004642963409424\n",
      "Current LR: [0.001]\n",
      "loss 0.12366366386413574\n",
      "Current LR: [0.001]\n",
      "loss 0.2766207754611969\n",
      "[6,  100] average loss for these 10 batches of 64 images is: 0.267\n",
      "total loss for validation set is 0.610\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.41134464740753174\n",
      "Current LR: [0.001]\n",
      "loss 0.2606522738933563\n",
      "Current LR: [0.001]\n",
      "loss 0.18236860632896423\n",
      "Current LR: [0.001]\n",
      "loss 0.2004747837781906\n",
      "Current LR: [0.001]\n",
      "loss 0.2615569829940796\n",
      "Current LR: [0.001]\n",
      "loss 0.2186049222946167\n",
      "Current LR: [0.001]\n",
      "loss 0.2387378215789795\n",
      "Current LR: [0.001]\n",
      "loss 0.3966999650001526\n",
      "Current LR: [0.001]\n",
      "loss 0.18216942250728607\n",
      "Current LR: [0.001]\n",
      "loss 0.30684658885002136\n",
      "[6,  110] average loss for these 10 batches of 64 images is: 0.266\n",
      "total loss for validation set is 1.087\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.16808448731899261\n",
      "Current LR: [0.001]\n",
      "loss 0.37412595748901367\n",
      "Current LR: [0.001]\n",
      "loss 0.2662724554538727\n",
      "Current LR: [0.001]\n",
      "loss 0.22148017585277557\n",
      "Current LR: [0.001]\n",
      "loss 0.3133990168571472\n",
      "Current LR: [0.001]\n",
      "loss 0.4722447395324707\n",
      "Current LR: [0.001]\n",
      "loss 0.4464007019996643\n",
      "Current LR: [0.001]\n",
      "loss 0.4036095440387726\n",
      "Current LR: [0.001]\n",
      "loss 0.3705368936061859\n",
      "Current LR: [0.001]\n",
      "loss 0.22185757756233215\n",
      "[6,  120] average loss for these 10 batches of 64 images is: 0.326\n",
      "total loss for validation set is 0.775\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.32916906476020813\n",
      "Current LR: [0.001]\n",
      "loss 0.2816218435764313\n",
      "Current LR: [0.001]\n",
      "loss 0.23775982856750488\n",
      "Current LR: [0.001]\n",
      "loss 0.38806432485580444\n",
      "Current LR: [0.001]\n",
      "loss 0.28459906578063965\n",
      "Current LR: [0.001]\n",
      "loss 0.3429674506187439\n",
      "Current LR: [0.001]\n",
      "loss 0.23203086853027344\n",
      "Current LR: [0.001]\n",
      "loss 0.3199089765548706\n",
      "Current LR: [0.001]\n",
      "loss 0.27535948157310486\n",
      "Current LR: [0.001]\n",
      "loss 0.294482946395874\n",
      "[6,  130] average loss for these 10 batches of 64 images is: 0.299\n",
      "total loss for validation set is 0.576\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.21128739416599274\n",
      "Current LR: [0.001]\n",
      "loss 0.21613112092018127\n",
      "Current LR: [0.001]\n",
      "loss 0.3918255567550659\n",
      "Current LR: [0.001]\n",
      "loss 0.12760135531425476\n",
      "Current LR: [0.001]\n",
      "loss 0.37263983488082886\n",
      "Current LR: [0.001]\n",
      "loss 0.3307545781135559\n",
      "Current LR: [0.001]\n",
      "loss 0.30959945917129517\n",
      "Current LR: [0.001]\n",
      "loss 0.6323310732841492\n",
      "Current LR: [0.001]\n",
      "loss 0.1943974494934082\n",
      "Current LR: [0.001]\n",
      "loss 0.1812339723110199\n",
      "[6,  140] average loss for these 10 batches of 64 images is: 0.297\n",
      "total loss for validation set is 0.847\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.11930321902036667\n",
      "Current LR: [0.001]\n",
      "loss 0.24918819963932037\n",
      "Current LR: [0.001]\n",
      "loss 0.13380183279514313\n",
      "Current LR: [0.001]\n",
      "loss 0.16922679543495178\n",
      "Current LR: [0.001]\n",
      "loss 0.1423831284046173\n",
      "Current LR: [0.001]\n",
      "loss 0.33127838373184204\n",
      "Current LR: [0.001]\n",
      "loss 0.39785492420196533\n",
      "Current LR: [0.001]\n",
      "loss 0.5257120132446289\n",
      "Current LR: [0.001]\n",
      "loss 0.21279571950435638\n",
      "Current LR: [0.001]\n",
      "loss 0.2162156105041504\n",
      "[6,  150] average loss for these 10 batches of 64 images is: 0.250\n",
      "total loss for validation set is 0.427\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2659187614917755\n",
      "Current LR: [0.001]\n",
      "loss 0.4347931444644928\n",
      "Current LR: [0.001]\n",
      "loss 0.2964284420013428\n",
      "Current LR: [0.001]\n",
      "loss 0.2883775532245636\n",
      "Current LR: [0.001]\n",
      "loss 0.16384950280189514\n",
      "Current LR: [0.001]\n",
      "loss 0.23199628293514252\n",
      "Current LR: [0.001]\n",
      "loss 0.1522282212972641\n",
      "Current LR: [0.001]\n",
      "loss 0.2641063630580902\n",
      "Current LR: [0.001]\n",
      "loss 0.16645535826683044\n",
      "Current LR: [0.001]\n",
      "loss 0.24296240508556366\n",
      "[6,  160] average loss for these 10 batches of 64 images is: 0.251\n",
      "total loss for validation set is 0.522\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.25103190541267395\n",
      "Current LR: [0.001]\n",
      "loss 0.21134348213672638\n",
      "Current LR: [0.001]\n",
      "loss 0.2003265917301178\n",
      "Current LR: [0.001]\n",
      "loss 0.2805052101612091\n",
      "Current LR: [0.001]\n",
      "loss 0.2743137776851654\n",
      "Current LR: [0.001]\n",
      "loss 0.19447723031044006\n",
      "Current LR: [0.001]\n",
      "loss 0.17482411861419678\n",
      "Current LR: [0.001]\n",
      "loss 0.18933582305908203\n",
      "Current LR: [0.001]\n",
      "loss 0.14094077050685883\n",
      "Current LR: [0.001]\n",
      "loss 0.5941116809844971\n",
      "Current LR: [0.001]\n",
      "loss 0.16010190546512604\n",
      "Current LR: [0.001]\n",
      "loss 0.10332314670085907\n",
      "Current LR: [0.001]\n",
      "loss 0.20144829154014587\n",
      "[7,   10] average loss for these 10 batches of 64 images is: 0.231\n",
      "total loss for validation set is 0.935\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.12549646198749542\n",
      "Current LR: [0.001]\n",
      "loss 0.2717759609222412\n",
      "Current LR: [0.001]\n",
      "loss 0.22739212214946747\n",
      "Current LR: [0.001]\n",
      "loss 0.2270916849374771\n",
      "Current LR: [0.001]\n",
      "loss 0.15275560319423676\n",
      "Current LR: [0.001]\n",
      "loss 0.24733948707580566\n",
      "Current LR: [0.001]\n",
      "loss 0.27545422315597534\n",
      "Current LR: [0.001]\n",
      "loss 0.38197413086891174\n",
      "Current LR: [0.001]\n",
      "loss 0.31681546568870544\n",
      "Current LR: [0.001]\n",
      "loss 0.29082825779914856\n",
      "[7,   20] average loss for these 10 batches of 64 images is: 0.252\n",
      "total loss for validation set is 0.346\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.25489792227745056\n",
      "Current LR: [0.001]\n",
      "loss 0.26250413060188293\n",
      "Current LR: [0.001]\n",
      "loss 0.22636516392230988\n",
      "Current LR: [0.001]\n",
      "loss 0.22181756794452667\n",
      "Current LR: [0.001]\n",
      "loss 0.14193902909755707\n",
      "Current LR: [0.001]\n",
      "loss 0.22780881822109222\n",
      "Current LR: [0.001]\n",
      "loss 0.2698710262775421\n",
      "Current LR: [0.001]\n",
      "loss 0.2522219121456146\n",
      "Current LR: [0.001]\n",
      "loss 0.21911947429180145\n",
      "Current LR: [0.001]\n",
      "loss 0.21942465007305145\n",
      "[7,   30] average loss for these 10 batches of 64 images is: 0.230\n",
      "total loss for validation set is 0.603\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.286655992269516\n",
      "Current LR: [0.001]\n",
      "loss 0.1361391842365265\n",
      "Current LR: [0.001]\n",
      "loss 0.16167189180850983\n",
      "Current LR: [0.001]\n",
      "loss 0.20504970848560333\n",
      "Current LR: [0.001]\n",
      "loss 0.43086233735084534\n",
      "Current LR: [0.001]\n",
      "loss 0.20525941252708435\n",
      "Current LR: [0.001]\n",
      "loss 0.1818791776895523\n",
      "Current LR: [0.001]\n",
      "loss 0.21193796396255493\n",
      "Current LR: [0.001]\n",
      "loss 0.4158240258693695\n",
      "Current LR: [0.001]\n",
      "loss 0.2597689628601074\n",
      "[7,   40] average loss for these 10 batches of 64 images is: 0.250\n",
      "total loss for validation set is 1.582\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2230769246816635\n",
      "Current LR: [0.001]\n",
      "loss 0.33234426379203796\n",
      "Current LR: [0.001]\n",
      "loss 0.23914124071598053\n",
      "Current LR: [0.001]\n",
      "loss 0.27601778507232666\n",
      "Current LR: [0.001]\n",
      "loss 0.14847537875175476\n",
      "Current LR: [0.001]\n",
      "loss 0.2180580198764801\n",
      "Current LR: [0.001]\n",
      "loss 0.20962537825107574\n",
      "Current LR: [0.001]\n",
      "loss 0.1964697539806366\n",
      "Current LR: [0.001]\n",
      "loss 0.2808666229248047\n",
      "Current LR: [0.001]\n",
      "loss 0.2649739682674408\n",
      "[7,   50] average loss for these 10 batches of 64 images is: 0.239\n",
      "total loss for validation set is 0.328\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.1380842626094818\n",
      "Current LR: [0.001]\n",
      "loss 0.20536234974861145\n",
      "Current LR: [0.001]\n",
      "loss 0.31584444642066956\n",
      "Current LR: [0.001]\n",
      "loss 0.21911202371120453\n",
      "Current LR: [0.001]\n",
      "loss 0.23950952291488647\n",
      "Current LR: [0.001]\n",
      "loss 0.11786080151796341\n",
      "Current LR: [0.001]\n",
      "loss 0.3463866114616394\n",
      "Current LR: [0.001]\n",
      "loss 0.32574495673179626\n",
      "Current LR: [0.001]\n",
      "loss 0.37661823630332947\n",
      "Current LR: [0.001]\n",
      "loss 0.2720663845539093\n",
      "[7,   60] average loss for these 10 batches of 64 images is: 0.256\n",
      "total loss for validation set is 0.703\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3273549973964691\n",
      "Current LR: [0.001]\n",
      "loss 0.25952839851379395\n",
      "Current LR: [0.001]\n",
      "loss 0.3529597818851471\n",
      "Current LR: [0.001]\n",
      "loss 0.25891798734664917\n",
      "Current LR: [0.001]\n",
      "loss 0.3441142737865448\n",
      "Current LR: [0.001]\n",
      "loss 0.2750408947467804\n",
      "Current LR: [0.001]\n",
      "loss 0.23412875831127167\n",
      "Current LR: [0.001]\n",
      "loss 0.17167530953884125\n",
      "Current LR: [0.001]\n",
      "loss 0.23094956576824188\n",
      "Current LR: [0.001]\n",
      "loss 0.2259470373392105\n",
      "[7,   70] average loss for these 10 batches of 64 images is: 0.268\n",
      "total loss for validation set is 0.841\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.17359282076358795\n",
      "Current LR: [0.001]\n",
      "loss 0.19610311090946198\n",
      "Current LR: [0.001]\n",
      "loss 0.360897958278656\n",
      "Current LR: [0.001]\n",
      "loss 0.40112829208374023\n",
      "Current LR: [0.001]\n",
      "loss 0.12699727714061737\n",
      "Current LR: [0.001]\n",
      "loss 0.1437142789363861\n",
      "Current LR: [0.001]\n",
      "loss 0.14750799536705017\n",
      "Current LR: [0.001]\n",
      "loss 0.3045596778392792\n",
      "Current LR: [0.001]\n",
      "loss 0.2508554458618164\n",
      "Current LR: [0.001]\n",
      "loss 0.2489578127861023\n",
      "[7,   80] average loss for these 10 batches of 64 images is: 0.235\n",
      "total loss for validation set is 0.295\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.4140473008155823\n",
      "Current LR: [0.001]\n",
      "loss 0.23733186721801758\n",
      "Current LR: [0.001]\n",
      "loss 0.1465052217245102\n",
      "Current LR: [0.001]\n",
      "loss 0.209092915058136\n",
      "Current LR: [0.001]\n",
      "loss 0.20358183979988098\n",
      "Current LR: [0.001]\n",
      "loss 0.3357093930244446\n",
      "Current LR: [0.001]\n",
      "loss 0.36302539706230164\n",
      "Current LR: [0.001]\n",
      "loss 0.26560935378074646\n",
      "Current LR: [0.001]\n",
      "loss 0.21334801614284515\n",
      "Current LR: [0.001]\n",
      "loss 0.46005669236183167\n",
      "[7,   90] average loss for these 10 batches of 64 images is: 0.285\n",
      "total loss for validation set is 0.811\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2737371623516083\n",
      "Current LR: [0.001]\n",
      "loss 0.24932095408439636\n",
      "Current LR: [0.001]\n",
      "loss 0.44667574763298035\n",
      "Current LR: [0.001]\n",
      "loss 0.2532842755317688\n",
      "Current LR: [0.001]\n",
      "loss 0.09971649199724197\n",
      "Current LR: [0.001]\n",
      "loss 0.3998716175556183\n",
      "Current LR: [0.001]\n",
      "loss 0.5837967991828918\n",
      "Current LR: [0.001]\n",
      "loss 0.29053977131843567\n",
      "Current LR: [0.001]\n",
      "loss 0.2924976646900177\n",
      "Current LR: [0.001]\n",
      "loss 0.45209935307502747\n",
      "[7,  100] average loss for these 10 batches of 64 images is: 0.334\n",
      "total loss for validation set is 0.321\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.5781462788581848\n",
      "Current LR: [0.001]\n",
      "loss 0.2992887794971466\n",
      "Current LR: [0.001]\n",
      "loss 0.26010408997535706\n",
      "Current LR: [0.001]\n",
      "loss 0.2504277527332306\n",
      "Current LR: [0.001]\n",
      "loss 0.3195298910140991\n",
      "Current LR: [0.001]\n",
      "loss 0.35687878727912903\n",
      "Current LR: [0.001]\n",
      "loss 0.1774778962135315\n",
      "Current LR: [0.001]\n",
      "loss 0.4995393753051758\n",
      "Current LR: [0.001]\n",
      "loss 0.28093329071998596\n",
      "Current LR: [0.001]\n",
      "loss 0.235235333442688\n",
      "[7,  110] average loss for these 10 batches of 64 images is: 0.326\n",
      "total loss for validation set is 0.443\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3029111921787262\n",
      "Current LR: [0.001]\n",
      "loss 0.3675449788570404\n",
      "Current LR: [0.001]\n",
      "loss 0.23590514063835144\n",
      "Current LR: [0.001]\n",
      "loss 0.24763798713684082\n",
      "Current LR: [0.001]\n",
      "loss 0.31848302483558655\n",
      "Current LR: [0.001]\n",
      "loss 0.23916536569595337\n",
      "Current LR: [0.001]\n",
      "loss 0.16748552024364471\n",
      "Current LR: [0.001]\n",
      "loss 0.24682100117206573\n",
      "Current LR: [0.001]\n",
      "loss 0.19828768074512482\n",
      "Current LR: [0.001]\n",
      "loss 0.21669743955135345\n",
      "[7,  120] average loss for these 10 batches of 64 images is: 0.254\n",
      "total loss for validation set is 0.715\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.1313951462507248\n",
      "Current LR: [0.001]\n",
      "loss 0.2711041569709778\n",
      "Current LR: [0.001]\n",
      "loss 0.27968159317970276\n",
      "Current LR: [0.001]\n",
      "loss 0.18986040353775024\n",
      "Current LR: [0.001]\n",
      "loss 0.16830594837665558\n",
      "Current LR: [0.001]\n",
      "loss 0.12494761496782303\n",
      "Current LR: [0.001]\n",
      "loss 0.23012550175189972\n",
      "Current LR: [0.001]\n",
      "loss 0.2456897646188736\n",
      "Current LR: [0.001]\n",
      "loss 0.21324023604393005\n",
      "Current LR: [0.001]\n",
      "loss 0.24124713242053986\n",
      "[7,  130] average loss for these 10 batches of 64 images is: 0.210\n",
      "total loss for validation set is 0.451\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.12644797563552856\n",
      "Current LR: [0.001]\n",
      "loss 0.36365702748298645\n",
      "Current LR: [0.001]\n",
      "loss 0.1363440304994583\n",
      "Current LR: [0.001]\n",
      "loss 0.28688475489616394\n",
      "Current LR: [0.001]\n",
      "loss 0.34209585189819336\n",
      "Current LR: [0.001]\n",
      "loss 0.2869808077812195\n",
      "Current LR: [0.001]\n",
      "loss 0.21753595769405365\n",
      "Current LR: [0.001]\n",
      "loss 0.20829564332962036\n",
      "Current LR: [0.001]\n",
      "loss 0.24627946317195892\n",
      "Current LR: [0.001]\n",
      "loss 0.29410532116889954\n",
      "[7,  140] average loss for these 10 batches of 64 images is: 0.251\n",
      "total loss for validation set is 0.639\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.18326613306999207\n",
      "Current LR: [0.001]\n",
      "loss 0.41689997911453247\n",
      "Current LR: [0.001]\n",
      "loss 0.21102003753185272\n",
      "Current LR: [0.001]\n",
      "loss 0.2904731035232544\n",
      "Current LR: [0.001]\n",
      "loss 0.16924986243247986\n",
      "Current LR: [0.001]\n",
      "loss 0.1977013647556305\n",
      "Current LR: [0.001]\n",
      "loss 0.27479761838912964\n",
      "Current LR: [0.001]\n",
      "loss 0.13736183941364288\n",
      "Current LR: [0.001]\n",
      "loss 0.20556609332561493\n",
      "Current LR: [0.001]\n",
      "loss 0.39147520065307617\n",
      "[7,  150] average loss for these 10 batches of 64 images is: 0.248\n",
      "total loss for validation set is 0.579\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.22505724430084229\n",
      "Current LR: [0.001]\n",
      "loss 0.2862433195114136\n",
      "Current LR: [0.001]\n",
      "loss 0.18441171944141388\n",
      "Current LR: [0.001]\n",
      "loss 0.21565528213977814\n",
      "Current LR: [0.001]\n",
      "loss 0.2897205948829651\n",
      "Current LR: [0.001]\n",
      "loss 0.1640302836894989\n",
      "Current LR: [0.001]\n",
      "loss 0.16346736252307892\n",
      "Current LR: [0.001]\n",
      "loss 0.1908411830663681\n",
      "Current LR: [0.001]\n",
      "loss 0.1543591469526291\n",
      "Current LR: [0.001]\n",
      "loss 0.24189606308937073\n",
      "[7,  160] average loss for these 10 batches of 64 images is: 0.212\n",
      "total loss for validation set is 1.091\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.6072347164154053\n",
      "Current LR: [0.001]\n",
      "loss 0.22699828445911407\n",
      "Current LR: [0.001]\n",
      "loss 0.2528824210166931\n",
      "Current LR: [0.001]\n",
      "loss 0.1978173553943634\n",
      "Current LR: [0.001]\n",
      "loss 0.2095055729150772\n",
      "Current LR: [0.001]\n",
      "loss 0.24133028090000153\n",
      "Current LR: [0.001]\n",
      "loss 0.23903386294841766\n",
      "Current LR: [0.001]\n",
      "loss 0.16126485168933868\n",
      "Current LR: [0.001]\n",
      "loss 0.33969786763191223\n",
      "Current LR: [0.001]\n",
      "loss 0.3254205584526062\n",
      "Current LR: [0.001]\n",
      "loss 0.29411962628364563\n",
      "Current LR: [0.001]\n",
      "loss 0.18529781699180603\n",
      "Current LR: [0.001]\n",
      "loss 0.24738021194934845\n",
      "[8,   10] average loss for these 10 batches of 64 images is: 0.244\n",
      "total loss for validation set is 0.373\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.1955089420080185\n",
      "Current LR: [0.001]\n",
      "loss 0.15173564851284027\n",
      "Current LR: [0.001]\n",
      "loss 0.2963257431983948\n",
      "Current LR: [0.001]\n",
      "loss 0.4149564504623413\n",
      "Current LR: [0.001]\n",
      "loss 0.17461036145687103\n",
      "Current LR: [0.001]\n",
      "loss 0.10553233325481415\n",
      "Current LR: [0.001]\n",
      "loss 0.25175195932388306\n",
      "Current LR: [0.001]\n",
      "loss 0.3414444327354431\n",
      "Current LR: [0.001]\n",
      "loss 0.15552806854248047\n",
      "Current LR: [0.001]\n",
      "loss 0.2860663831233978\n",
      "[8,   20] average loss for these 10 batches of 64 images is: 0.237\n",
      "total loss for validation set is 1.219\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3927029073238373\n",
      "Current LR: [0.001]\n",
      "loss 0.32124564051628113\n",
      "Current LR: [0.001]\n",
      "loss 0.24660557508468628\n",
      "Current LR: [0.001]\n",
      "loss 0.2792302966117859\n",
      "Current LR: [0.001]\n",
      "loss 0.23973891139030457\n",
      "Current LR: [0.001]\n",
      "loss 0.2138114869594574\n",
      "Current LR: [0.001]\n",
      "loss 0.21843822300434113\n",
      "Current LR: [0.001]\n",
      "loss 0.14968253672122955\n",
      "Current LR: [0.001]\n",
      "loss 0.11577785015106201\n",
      "Current LR: [0.001]\n",
      "loss 0.2719634175300598\n",
      "[8,   30] average loss for these 10 batches of 64 images is: 0.245\n",
      "total loss for validation set is 0.330\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.20361153781414032\n",
      "Current LR: [0.001]\n",
      "loss 0.17396396398544312\n",
      "Current LR: [0.001]\n",
      "loss 0.2442425787448883\n",
      "Current LR: [0.001]\n",
      "loss 0.2149646133184433\n",
      "Current LR: [0.001]\n",
      "loss 0.444511741399765\n",
      "Current LR: [0.001]\n",
      "loss 0.15555104613304138\n",
      "Current LR: [0.001]\n",
      "loss 0.3744165897369385\n",
      "Current LR: [0.001]\n",
      "loss 0.12111275643110275\n",
      "Current LR: [0.001]\n",
      "loss 0.3659137785434723\n",
      "Current LR: [0.001]\n",
      "loss 0.2141977846622467\n",
      "[8,   40] average loss for these 10 batches of 64 images is: 0.251\n",
      "total loss for validation set is 0.386\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.1568974256515503\n",
      "Current LR: [0.001]\n",
      "loss 0.19871683418750763\n",
      "Current LR: [0.001]\n",
      "loss 0.15520983934402466\n",
      "Current LR: [0.001]\n",
      "loss 0.19326446950435638\n",
      "Current LR: [0.001]\n",
      "loss 0.1993151307106018\n",
      "Current LR: [0.001]\n",
      "loss 0.32409054040908813\n",
      "Current LR: [0.001]\n",
      "loss 0.25481584668159485\n",
      "Current LR: [0.001]\n",
      "loss 0.24055571854114532\n",
      "Current LR: [0.001]\n",
      "loss 0.16177885234355927\n",
      "Current LR: [0.001]\n",
      "loss 0.2901362180709839\n",
      "[8,   50] average loss for these 10 batches of 64 images is: 0.217\n",
      "total loss for validation set is 0.495\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2579730153083801\n",
      "Current LR: [0.001]\n",
      "loss 0.08514389395713806\n",
      "Current LR: [0.001]\n",
      "loss 0.3589619994163513\n",
      "Current LR: [0.001]\n",
      "loss 0.11021944880485535\n",
      "Current LR: [0.001]\n",
      "loss 0.19226554036140442\n",
      "Current LR: [0.001]\n",
      "loss 0.2713651955127716\n",
      "Current LR: [0.001]\n",
      "loss 0.5219943523406982\n",
      "Current LR: [0.001]\n",
      "loss 0.21906614303588867\n",
      "Current LR: [0.001]\n",
      "loss 0.36582058668136597\n",
      "Current LR: [0.001]\n",
      "loss 0.1591011881828308\n",
      "[8,   60] average loss for these 10 batches of 64 images is: 0.254\n",
      "total loss for validation set is 0.308\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.228127583861351\n",
      "Current LR: [0.001]\n",
      "loss 0.21915364265441895\n",
      "Current LR: [0.001]\n",
      "loss 0.19104032218456268\n",
      "Current LR: [0.001]\n",
      "loss 0.42788270115852356\n",
      "Current LR: [0.001]\n",
      "loss 0.3922298550605774\n",
      "Current LR: [0.001]\n",
      "loss 0.33320677280426025\n",
      "Current LR: [0.001]\n",
      "loss 0.3084355294704437\n",
      "Current LR: [0.001]\n",
      "loss 0.1642083376646042\n",
      "Current LR: [0.001]\n",
      "loss 0.13783442974090576\n",
      "Current LR: [0.001]\n",
      "loss 0.18217401206493378\n",
      "[8,   70] average loss for these 10 batches of 64 images is: 0.258\n",
      "total loss for validation set is 0.716\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.2107066661119461\n",
      "Current LR: [0.001]\n",
      "loss 0.35587576031684875\n",
      "Current LR: [0.001]\n",
      "loss 0.20453722774982452\n",
      "Current LR: [0.001]\n",
      "loss 0.19029757380485535\n",
      "Current LR: [0.001]\n",
      "loss 0.18273617327213287\n",
      "Current LR: [0.001]\n",
      "loss 0.18523265421390533\n",
      "Current LR: [0.001]\n",
      "loss 0.22342202067375183\n",
      "Current LR: [0.001]\n",
      "loss 0.17757020890712738\n",
      "Current LR: [0.001]\n",
      "loss 0.24124544858932495\n",
      "Current LR: [0.001]\n",
      "loss 0.14036643505096436\n",
      "[8,   80] average loss for these 10 batches of 64 images is: 0.211\n",
      "total loss for validation set is 0.699\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.1320715844631195\n",
      "Current LR: [0.001]\n",
      "loss 0.29013094305992126\n",
      "Current LR: [0.001]\n",
      "loss 0.29454079270362854\n",
      "Current LR: [0.001]\n",
      "loss 0.10032188147306442\n",
      "Current LR: [0.001]\n",
      "loss 0.1785854548215866\n",
      "Current LR: [0.001]\n",
      "loss 0.26660093665122986\n",
      "Current LR: [0.001]\n",
      "loss 0.26992303133010864\n",
      "Current LR: [0.001]\n",
      "loss 0.4268414080142975\n",
      "Current LR: [0.001]\n",
      "loss 0.3019462823867798\n",
      "Current LR: [0.001]\n",
      "loss 0.24513103067874908\n",
      "[8,   90] average loss for these 10 batches of 64 images is: 0.251\n",
      "total loss for validation set is 0.972\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3578040599822998\n",
      "Current LR: [0.001]\n",
      "loss 0.2324690818786621\n",
      "Current LR: [0.001]\n",
      "loss 0.3702123761177063\n",
      "Current LR: [0.001]\n",
      "loss 0.22082112729549408\n",
      "Current LR: [0.001]\n",
      "loss 0.2392735481262207\n",
      "Current LR: [0.001]\n",
      "loss 0.25729256868362427\n",
      "Current LR: [0.001]\n",
      "loss 0.22166654467582703\n",
      "Current LR: [0.001]\n",
      "loss 0.24818821251392365\n",
      "Current LR: [0.001]\n",
      "loss 0.31271541118621826\n",
      "Current LR: [0.001]\n",
      "loss 0.1917906105518341\n",
      "[8,  100] average loss for these 10 batches of 64 images is: 0.265\n",
      "total loss for validation set is 0.313\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.3064889907836914\n",
      "Current LR: [0.001]\n",
      "loss 0.20921438932418823\n",
      "Current LR: [0.001]\n",
      "loss 0.19621308147907257\n",
      "Current LR: [0.001]\n",
      "loss 0.36961838603019714\n",
      "Current LR: [0.001]\n",
      "loss 0.16896063089370728\n",
      "Current LR: [0.001]\n",
      "loss 0.11149462312459946\n",
      "Current LR: [0.001]\n",
      "loss 0.2955414056777954\n",
      "Current LR: [0.001]\n",
      "loss 0.3017285466194153\n",
      "Current LR: [0.001]\n",
      "loss 0.3748025894165039\n",
      "Current LR: [0.001]\n",
      "loss 0.3306705355644226\n",
      "[8,  110] average loss for these 10 batches of 64 images is: 0.266\n",
      "total loss for validation set is 0.687\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.24217188358306885\n",
      "Current LR: [0.001]\n",
      "loss 0.2507665455341339\n",
      "Current LR: [0.001]\n",
      "loss 0.3511316180229187\n",
      "Current LR: [0.001]\n",
      "loss 0.2619715929031372\n",
      "Current LR: [0.001]\n",
      "loss 0.27616339921951294\n",
      "Current LR: [0.001]\n",
      "loss 0.17830589413642883\n",
      "Current LR: [0.001]\n",
      "loss 0.29258236289024353\n",
      "Current LR: [0.001]\n",
      "loss 0.14815044403076172\n",
      "Current LR: [0.001]\n",
      "loss 0.2225726842880249\n",
      "Current LR: [0.001]\n",
      "loss 0.21837088465690613\n",
      "[8,  120] average loss for these 10 batches of 64 images is: 0.244\n",
      "total loss for validation set is 0.355\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.39886170625686646\n",
      "Current LR: [0.001]\n",
      "loss 0.3684397041797638\n",
      "Current LR: [0.001]\n",
      "loss 0.16223715245723724\n",
      "Current LR: [0.001]\n",
      "loss 0.26491832733154297\n",
      "Current LR: [0.001]\n",
      "loss 0.17680823802947998\n",
      "Current LR: [0.001]\n",
      "loss 0.19940684735774994\n",
      "Current LR: [0.001]\n",
      "loss 0.32294556498527527\n",
      "Current LR: [0.001]\n",
      "loss 0.20786914229393005\n",
      "Current LR: [0.001]\n",
      "loss 0.3127715587615967\n",
      "Current LR: [0.001]\n",
      "loss 0.21564404666423798\n",
      "[8,  130] average loss for these 10 batches of 64 images is: 0.263\n",
      "total loss for validation set is 0.333\n",
      "Current LR: [0.001]\n",
      "Current LR: [0.001]\n",
      "loss 0.4895618259906769\n",
      "Current LR: [0.001]\n",
      "loss 0.16929155588150024\n",
      "Current LR: [0.001]\n",
      "loss 0.24387651681900024\n",
      "Current LR: [0.001]\n",
      "loss 0.25236088037490845\n",
      "Current LR: [0.001]\n",
      "loss 0.23389317095279694\n",
      "Current LR: [0.001]\n",
      "loss 0.2521685063838959\n",
      "Current LR: [0.001]\n",
      "loss 0.21435260772705078\n",
      "Current LR: [0.001]\n",
      "loss 0.19213180243968964\n",
      "Current LR: [0.001]\n",
      "loss 0.18205298483371735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# implement the training loop\n",
    "import copy\n",
    "train_overall_loss = 100 # arbitrary big number\n",
    "val_running_loss = 100 # arbitrary big number\n",
    "best_model_wts = copy.deepcopy(model.state_dict()) \n",
    "\n",
    "\n",
    "for epoch in range(epoch_range):\n",
    "  running_loss = 0.0 \n",
    "  for i, data in enumerate(trainloader,0): #trainloader = full trainset, trainloader_dataset_2 = small sample of trainset \n",
    "    # i is sets of images of batch size # data = [images, labels]\n",
    "    #inputs, labels = data\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    #print(outputs,labels)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step() # does the update\n",
    "    scheduler.step()\n",
    "    print('Current LR:', scheduler.get_last_lr()) \n",
    "\n",
    "    # if cyclical LR\n",
    "    #if step == False:\n",
    "    #  scheduler.step()\n",
    "    #  print('Current LR:', scheduler.get_last_lr()) \n",
    "    # add to running loss\n",
    "    running_loss += loss.item() \n",
    "    print('loss', loss.item())\n",
    "\n",
    "    if i % 10 == 9: # every 10 batches of 64 images print running loss for training \n",
    "      # print statistics\n",
    "      print('[%d,%5d] average loss for these 10 batches of 64 images is: %.3f' % (epoch + 1, i + 1 , running_loss/10))\n",
    "      running_loss = 0\n",
    "    \n",
    "    # for plotting of loss of training set over time\n",
    "    training_loss_vector_y.append(loss.item()) # vector of training losses\n",
    "    training_loss_vector_x.append((i+1)*64/5216 + (epoch) ) # x axis is number of images\n",
    "\n",
    "    \n",
    "    if i % 10 == 9: # i.e. every 10 batches of 64 test on val set \n",
    "      # calculate loss on validation set\n",
    "      val_loss = 0.0\n",
    "      with torch.no_grad():\n",
    "        for val_data in valloader: # i.e. iterate over batches of data in the val set\n",
    "          val_images, val_labels = val_data[0].to(device), val_data[1].to(device) # each data is a batch of 1000 images/labels \n",
    "          model.eval()\n",
    "          val_outputs = model(val_images)\n",
    "          val_loss_mid = criterion(val_outputs,val_labels)\n",
    "          val_loss += val_loss_mid.item()\n",
    "          validation_loss_vector_y.append(val_loss)\n",
    "          validation_loss_vector_x.append((i+1)*64/5216 + (epoch)) # generally x.append((i+1)*batchsize/number_of_training_images + (epoch)) gives x axis in units of epochs\n",
    "          # need to save best version on validation set\n",
    "          if (val_loss < val_running_loss):\n",
    "            print('saving best model')\n",
    "            model_save_name = 'model_best_on_val.pt'\n",
    "            path = F\"/content/gdrive/My Drive/Week 3/{model_save_name}\" \n",
    "            torch.save(model.state_dict(), path)\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            val_running_loss = val_loss\n",
    "      print('total loss for validation set is %.3f' % (val_loss) )\n",
    "      print('Current LR:', scheduler.get_last_lr()) \n",
    "\n",
    "    # Decay step up Learning Rate\n",
    "    #if step == True:\n",
    "    #  scheduler.step()\n",
    "\n",
    "    # print parameters\n",
    "    #for name, param in model.named_parameters():  \n",
    "    #  print(name,param)\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "8UjH5ry8C5zs",
    "outputId": "7c17bc95-20db-4b36-e54d-75a663aee0f9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "#plt.plot(validation_loss_vector_x,validation_loss_vector_y, label = \"val\")\n",
    "plt.plot(training_loss_vector_x,training_loss_vector_y, label = \"train\")\n",
    "z = np.polyfit(training_loss_vector_x,training_loss_vector_y, 2)\n",
    "x = np.linspace(min(training_loss_vector_x),max(training_loss_vector_x),100)\n",
    "#p = np.poly1d(z)\n",
    "#plt.plot(x, p(x), label = \"train_fit\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plot accuracy vs learning rate - for setting LR\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(learning_rate_vector,accuracy_test_vector)\n",
    "plt.xlabel('LR')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "cStjO6jzRuTd",
    "outputId": "4597baec-dc00-493b-d82e-ba7ff0a97288"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f313c1c0cba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'final_model_report_03jan.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mF\"/content/gdrive/My Drive/Week 3/{model_save_name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "\n",
    "model_save_name = 'final_model_report_03jan.pt'\n",
    "path = F\"/content/gdrive/My Drive/Week 3/{model_save_name}\" \n",
    "torch.save(model.state_dict(), path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49GqAFnC4ky1",
    "outputId": "f1994f78-64d2-4fec-8181-c2b39dd86d9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load saved model\n",
    "\n",
    "model_save_name = 'model_best_on_val.pt'\n",
    "#model_save_name = 'final_model_report.pt'\n",
    "path = F\"/content/gdrive/My Drive/Week 3/{model_save_name}\"\n",
    "model.load_state_dict(torch.load(path, map_location = torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBSfqvKy4ZwB"
   },
   "outputs": [],
   "source": [
    "# load model immediately\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCWGp4Vadl4e",
    "outputId": "7764c5b6-de8f-4fcb-fb76-843e664428a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1281   60]\n",
      " [1090 2785]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class | Class Accuracy\n",
      "Normal | 95.52572706935123\n",
      "Pneumonia | 71.87096774193549\n"
     ]
    }
   ],
   "source": [
    "# plot confusion matrix for training set\n",
    "\n",
    "\n",
    "\n",
    "number_classes = 2\n",
    "\n",
    "# initialise prediction and label lists(tensors)\n",
    "predlist=torch.zeros(0,dtype=torch.long, device='cuda')\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device='cuda')\n",
    "\n",
    "with torch.no_grad(): # i.e. no point wasting time calculating gradient don't need it here\n",
    "  for data in trainloader: # i.e. iterate over batches of data in the test set\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(images) # run the model with the test batch file of 64 images\n",
    "    _, predicted = torch.max(outputs, 1) # predicted is tensor containing indices of predicted classes\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in trainloader:\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1) # predicted is tensor containing indices of predicted classes\n",
    "    # Append batch prediction results\n",
    "    predlist=torch.cat([predlist,predicted.view(-1).to(device)])\n",
    "    lbllist=torch.cat([lbllist,labels.view(-1).to(device)])\n",
    "\n",
    "# Confusion matrix\n",
    "predlist = predlist.cpu()\n",
    "lbllist = lbllist.cpu()\n",
    "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "conf_mat = np.array(conf_mat)\n",
    "print(conf_mat)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(conf_mat, cmap=\"YlGn\")\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_yticks(np.arange(len(classes)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticklabels(classes)\n",
    "plt.xlabel('Predicted class')\n",
    "plt.ylabel('True class')\n",
    "\n",
    "# Create colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax, cmap=\"YlGn\")\n",
    "cbar.ax.set_ylabel('', rotation=-90, va=\"bottom\")\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"right\", rotation_mode=\"anchor\", size)\n",
    "\n",
    "# Loop over data dimensions and create text annotations \n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        text = ax.text(j, i, conf_mat[i, j], ha=\"center\", va=\"center\", color=\"r\")\n",
    "\n",
    "ax.set_title(\"Confusion matrix\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
    "print('Class' + ' | ' + 'Class Accuracy')\n",
    "for i in range(len(classes)):\n",
    "  print(classes[i] + ' | ' + str(class_accuracy[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b5ikcyhtLzh",
    "outputId": "6ed5108d-e4cf-41d0-ca72-4670b165f660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[159  75]\n",
      " [116 274]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class | Class Accuracy\n",
      "Normal | 67.94871794871794\n",
      "Pneumonia | 70.25641025641026\n"
     ]
    }
   ],
   "source": [
    "# plot confusion matrix for test set\n",
    "\n",
    "number_classes = 2\n",
    "\n",
    "# initialise prediction and label lists(tensors)\n",
    "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "\n",
    "with torch.no_grad(): # i.e. no point wasting time calculating gradient don't need it here\n",
    "  for data in testloader: # i.e. iterate over batches of data in the test set\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(images) # run the model with the test batch file of 64 images\n",
    "    _, predicted = torch.max(outputs, 1) # predicted is tensor containing indices of predicted classes\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in testloader:\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1) # predicted is tensor containing indices of predicted classes\n",
    "    # Append batch prediction results\n",
    "    predlist=torch.cat([predlist,predicted.view(-1).to(device)])\n",
    "    lbllist=torch.cat([lbllist,labels.view(-1).to(device)])\n",
    "\n",
    "# Confusion matrix\n",
    "predlist = predlist.cpu()\n",
    "lbllist = lbllist.cpu()\n",
    "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "conf_mat = np.array(conf_mat)\n",
    "print(conf_mat)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "im = ax.imshow(conf_mat, cmap=\"YlGn\")\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_yticks(np.arange(len(classes)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticklabels(classes, size = 15)\n",
    "plt.xlabel('Predicted class')\n",
    "plt.ylabel('True class')\n",
    "\n",
    "# Create colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax, cmap=\"YlGn\")\n",
    "cbar.ax.set_ylabel('', rotation=-90, va=\"bottom\", size = 15)\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=0, ha=\"center\", rotation_mode=\"anchor\", size = 15)\n",
    "\n",
    "# Loop over data dimensions and create text annotations \n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        text = ax.text(j, i, conf_mat[i, j], ha=\"center\", va=\"center\", color=\"r\", size = 15)\n",
    "\n",
    "ax.set_title(\"Confusion matrix\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
    "print('Class' + ' | ' + 'Class Accuracy')\n",
    "for i in range(len(classes)):\n",
    "  print(classes[i] + ' | ' + str(class_accuracy[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4yJZGb0Xwdx",
    "outputId": "bbf931ca-677a-437d-9dc6-5e8390521971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model of test images: 69 %\n",
      "F1 micro score is \n",
      "0.6923076923076923\n",
      "tau is \n",
      "0.4465073754059537\n",
      "p value is \n",
      "7.590631652249769e-29\n"
     ]
    }
   ],
   "source": [
    "# test on entire test dataset\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "predicted_master = np.empty(0)\n",
    "true_master = np.empty(0)\n",
    "\n",
    "with torch.no_grad(): # i.e. no point wasting time calculating gradient don't need it here\n",
    "  for data in testloader: # i.e. iterate over batches of data in the test set\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(images) # run the model with the test batch file of 64 images\n",
    "    _, predicted = torch.max(outputs, 1) # predicted is tensor containing indices of predicted classes\n",
    "    total += labels.size(0) # .size(0) gives the number of rows, .size(1) gives the number of columns\n",
    "    # here labels is a tensor of size 64, correspondning to 64 images\n",
    "    # therefore each run of loop adds 64 images that have been analysed\n",
    "    correct += (predicted == labels).sum().item() # this adds up total number of correct predictions in this batch of 64\n",
    "    # needed for f1 score\n",
    "    predicted_master = np.concatenate((predicted_master,predicted.cpu().numpy()),axis=None)\n",
    "    true_master = np.concatenate((true_master,labels.cpu().numpy()),axis=None)\n",
    "print('Accuracy of the model of test images: %d %%' % (100 * correct/total))\n",
    "\n",
    "# F1 score\n",
    "f1_micro_score = f1_score(true_master, predicted_master, average = 'micro')\n",
    "print('F1 micro score is ')\n",
    "print(f1_micro_score)\n",
    "\n",
    "# Kendall tau score\n",
    "tau, p_value = stats.kendalltau(true_master, predicted_master)\n",
    "\n",
    "print('tau is ')\n",
    "print(tau)\n",
    "\n",
    "print('p value is ')\n",
    "print(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIMKOTTw9luE"
   },
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(true_master, predicted_master, pos_label=1)\n",
    "auc_score = roc_auc_score(true_master,predicted_master)\n",
    "\n",
    "# plot curve\n",
    "plt.figure()\n",
    "plt.scatter(fpr,tpr,marker = \"x\")\n",
    "z = np.polyfit(fpr,tpr, 2)\n",
    "x = np.linspace(min(fpr),max(fpr),100)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(x, p(x))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "# plot x = y\n",
    "q = np.poly1d([1,0])\n",
    "plt.plot(x,q(x),'--')\n",
    "plt.plot()\n",
    "plt.show()\n",
    "\n",
    "print('Area under curve is ' + str(auc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MkPduhzUUE0B"
   },
   "outputs": [],
   "source": [
    "# accuracy on val set\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad(): # i.e. no point wasting time calculating gradient don't need it here\n",
    "  for data in valloader: # i.e. iterate over batches of data in the test set\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(inputs) # run the model with the test batch file of 64 images\n",
    "    _, predicted = torch.max(outputs, 1) # predicted is tensor containing indices of predicted classes\n",
    "    total += labels.size(0) # .size(0) gives the number of rows, .size(1) gives the number of columns\n",
    "    # here labels is a tensor of size 64, correspondning to 64 images\n",
    "    # therefore each run of loop adds 64 images that have been analysed\n",
    "    correct += (predicted == labels).sum().item() # this adds up total number of correct predictions in this batch of 64\n",
    "    # needed for f1 score\n",
    "print('Accuracy of the model on validation images: %d %%' % (100 * correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tl5BqxE8XMSH"
   },
   "outputs": [],
   "source": [
    "# test best model for val set -> on val set\n",
    "\n",
    "model_save_name = 'model_best_on_val.pt'\n",
    "path = F\"/content/gdrive/My Drive/Week 3/{model_save_name}\"\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "# run this model on test and val\n",
    "\n",
    "# accuracy test\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad(): # i.e. no point wasting time calculating gradient don't need it here\n",
    "  for data in valloader: # i.e. iterate over batches of data in the test set\n",
    "    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(inputs) # run the model with the test batch file of 64 images\n",
    "    _, predicted = torch.max(outputs, 1) # predicted is tensor containing indices of predicted classes\n",
    "    total += labels.size(0) # .size(0) gives the number of rows, .size(1) gives the number of columns\n",
    "    # here labels is a tensor of size 64, correspondning to 64 images\n",
    "    # therefore each run of loop adds 64 images that have been analysed\n",
    "    correct += (predicted == labels).sum().item() # this adds up total number of correct predictions in this batch of 64\n",
    "    # needed for f1 score\n",
    "print('Accuracy of the model on validation images: %d %%' % (100 * correct/total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ru39EZvNdj4v"
   },
   "outputs": [],
   "source": [
    "# test best model on val set --> on the test set\n",
    "\n",
    "model_save_name = 'model_best_on_val.pt'\n",
    "path = F\"/content/gdrive/My Drive/Week 3/{model_save_name}\"\n",
    "model.load_state_dict(torch.load(path))\n",
    "\n",
    "# plot confusion matrix\n",
    "number_classes = 2\n",
    "\n",
    "# initialise prediction and label lists(tensors)\n",
    "predlist=torch.zeros(0,dtype=torch.long, device='cuda')\n",
    "lbllist=torch.zeros(0,dtype=torch.long, device='cuda')\n",
    "\n",
    "with torch.no_grad(): # i.e. no point wasting time calculating gradient don't need it here\n",
    "  for data in testloader: # i.e. iterate over batches of data in the test set\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(images) # run the model with the test batch file of 64 images\n",
    "    _, predicted = torch.max(outputs, 1) # predicted is tensor containing indices of predicted classes\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in testloader:\n",
    "    images, labels = data[0].to(device), data[1].to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1) # predicted is tensor containing indices of predicted classes\n",
    "    # Append batch prediction results\n",
    "    predlist=torch.cat([predlist,predicted.view(-1).to(device)])\n",
    "    lbllist=torch.cat([lbllist,labels.view(-1).to(device)])\n",
    "\n",
    "# Confusion matrix\n",
    "predlist = predlist.cpu()\n",
    "lbllist = lbllist.cpu()\n",
    "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
    "conf_mat = np.array(conf_mat)\n",
    "print(conf_mat)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(conf_mat, cmap=\"YlGn\")\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_yticks(np.arange(len(classes)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticklabels(classes)\n",
    "plt.xlabel('Predicted class')\n",
    "plt.ylabel('True class')\n",
    "\n",
    "# Create colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax, cmap=\"YlGn\")\n",
    "cbar.ax.set_ylabel('', rotation=-90, va=\"bottom\")\n",
    "\n",
    "# Rotate the tick labels and set their alignment.\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations \n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        text = ax.text(j, i, conf_mat[i, j], ha=\"center\", va=\"center\", color=\"r\")\n",
    "\n",
    "ax.set_title(\"Confusion matrix\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
    "print('Class' + ' | ' + 'Class Accuracy')\n",
    "for i in range(len(classes)):\n",
    "  print(classes[i] + ' | ' + str(class_accuracy[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7CDvH-mo-Su"
   },
   "outputs": [],
   "source": [
    "print(predicted_master)\n",
    "print(true_master)\n",
    "print(len(predicted_master))\n",
    "print(len(true_master))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pneumonia_CNN_model_Report_edit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
